{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T12:29:07.059804Z",
     "start_time": "2022-11-13T12:29:00.724523Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "#from create_dataset import CreateDataset\n",
    "\n",
    "from models import GNNModel\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FastCover/\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T12:29:07.136492Z",
     "start_time": "2022-11-13T12:29:07.112294Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_SAVE_TRAINS_CHECKPOINTS = 'runs/checkpoints/'\n",
    "PATH_SAVE_TRAINS = 'runs/'\n",
    "PATH_TRAIN = '../FastCover/data/ER_graphs/train/'\n",
    "\n",
    "num_features = 1\n",
    "num_classes  = 2\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "optimizer_name = \"Adam\"\n",
    "lr = 1e-3\n",
    "epochs = 20\n",
    "\n",
    "SEED = 13\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#layers = [}\"GCN\", \"GAT\",\"GraphConv\"]\n",
    "layers = [\"SAGE\"]\n",
    "\n",
    "Models = [GNNModel(c_in = 1, c_hidden = 100, c_out = 2, num_layers = 2, layer_name = layer_name, dp_rate=0.1) for \n",
    "         layer_name in layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T12:29:07.853849Z",
     "start_time": "2022-11-13T12:29:07.167376Z"
    }
   },
   "outputs": [],
   "source": [
    "ERInstances = [graph for graph in os.listdir(PATH_TRAIN+'pkl')]\n",
    "graphs = []\n",
    "for er in ERInstances:\n",
    "    graph = igraph.Graph().Read_Pickle(PATH_TRAIN + 'pkl/'+er)\n",
    "    graphs.append(graph.to_networkx())    \n",
    "\n",
    "OptInstances = [graph for graph in os.listdir(PATH_TRAIN+'optimal')]\n",
    "Solutions = []\n",
    "for er in OptInstances:\n",
    "    opt = []\n",
    "    with open(PATH_TRAIN+'optimal/'+er) as f:\n",
    "        for line in f.readlines():\n",
    "            opt.append(int(line.replace(\"\\n\", \"\")))\n",
    "    Solutions.append(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T12:29:26.619013Z",
     "start_time": "2022-11-13T12:29:26.318228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 27., 102., 213., 252., 102., 156.,  88.,  48.,  10.,   2.]),\n",
       " array([ 3. ,  4.8,  6.6,  8.4, 10.2, 12. , 13.8, 15.6, 17.4, 19.2, 21. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(nx.degree(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T15:23:44.358172Z",
     "start_time": "2022-11-13T15:23:44.280431Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_TEST = \"../BRKGA/instances/Erdos/txt/\"\n",
    "Graphs = [graph for graph in os.listdir(PATH_TO_TEST)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T15:23:45.449402Z",
     "start_time": "2022-11-13T15:23:45.429987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ER_10000_0.txt',\n",
       " 'ER_10000_1.txt',\n",
       " 'ER_10000_2.txt',\n",
       " 'ER_10000_3.txt',\n",
       " 'ER_10000_4.txt',\n",
       " 'ER_20000_0.txt',\n",
       " 'ER_20000_1.txt',\n",
       " 'ER_20000_2.txt',\n",
       " 'ER_20000_3.txt',\n",
       " 'ER_20000_4.txt',\n",
       " 'ER_2000_0.txt',\n",
       " 'ER_2000_1.txt',\n",
       " 'ER_2000_2.txt',\n",
       " 'ER_2000_3.txt',\n",
       " 'ER_2000_4.txt',\n",
       " 'ER_2000_5.txt',\n",
       " 'ER_2000_6.txt',\n",
       " 'ER_2000_7.txt',\n",
       " 'ER_2000_8.txt',\n",
       " 'ER_2000_9.txt',\n",
       " 'ER_30000_0.txt',\n",
       " 'ER_30000_1.txt',\n",
       " 'ER_30000_2.txt',\n",
       " 'ER_50000_0.txt',\n",
       " 'ER_50000_1.txt',\n",
       " 'ER_50000_2.txt',\n",
       " 'ER_5000_0.txt',\n",
       " 'ER_5000_1.txt',\n",
       " 'ER_5000_2.txt',\n",
       " 'ER_5000_3.txt',\n",
       " 'ER_5000_4.txt',\n",
       " 'ER_5000_5.txt',\n",
       " 'ER_5000_6.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T11:01:46.214842Z",
     "start_time": "2022-11-08T11:01:46.192840Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    \"\"\"GIN\"\"\"\n",
    "    def __init__(self, dim_h, num_features, num_classes):\n",
    "        super(GIN, self).__init__()\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(num_features, dim_h),\n",
    "                       BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        \n",
    "        self.lin1 = Linear(dim_h*3, dim_h*3)\n",
    "        self.lin2 = Linear(dim_h*3, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Node embeddings \n",
    "        h1 = self.conv1(x, edge_index)\n",
    "        h2 = self.conv2(h1, edge_index)\n",
    "        h3 = self.conv3(h2, edge_index)\n",
    "        #print(h3.detach().numpy().shape)\n",
    "        x = Linear(2, 1000)(h3)\n",
    "        print(x.detach().numpy().shape)\n",
    "        # num_nodes x 1\n",
    "        # aquí le tengo que aplicar una función para que cambie a num_nodes x num_classes\n",
    "        # y ya solo regresar el softmax\n",
    "        #return h3\n",
    "\n",
    "        # Graph-level readout\n",
    "        h1 = global_add_pool(h1, batch)\n",
    "        h2 = global_add_pool(h2, batch)\n",
    "        h3 = global_add_pool(h3, batch)\n",
    "        # 1 x 1 due to global pooling\n",
    "        \n",
    "        print(h3.detach().numpy().shape)\n",
    "\n",
    "        # Concatenate graph embeddings\n",
    "        h = torch.cat((h1, h2, h3), dim=1)\n",
    "        #3x1 due to concat\n",
    "\n",
    "        # Classifier\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        #3 x num_classes due to \n",
    "        \n",
    "        return h, F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:47:35.044720Z",
     "start_time": "2022-11-05T13:47:35.035769Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:53:10.263795Z",
     "start_time": "2022-11-05T13:53:10.250744Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(Graphs_Train, batch_size=1)\n",
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:53:10.955578Z",
     "start_time": "2022-11-05T13:53:10.949577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 9982], num_nodes=1000, x=[1000, 1], y=[1000], num_classes=[1], batch=[1000], ptr=[2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T11:02:07.788732Z",
     "start_time": "2022-11-08T11:02:07.662737Z"
    }
   },
   "outputs": [],
   "source": [
    "Graphs_Train = Convert2DataSet(graphs, Solutions)\n",
    "num_features = Graphs_Train[0].num_features\n",
    "num_classes = Graphs_Train[0].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T10:53:40.279621Z",
     "start_time": "2022-11-09T10:53:40.261672Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T10:47:07.298000Z",
     "start_time": "2022-11-09T10:47:07.238090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T10:51:34.570370Z",
     "start_time": "2022-11-09T10:51:34.555316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0].number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T15:08:53.442190Z",
     "start_time": "2022-11-05T15:08:53.422193Z"
    }
   },
   "outputs": [],
   "source": [
    "gin = GIN(dim_h = 1, num_classes = num_classes, num_features = num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:31:17.209075Z",
     "start_time": "2022-11-05T13:31:17.201075Z"
    }
   },
   "outputs": [],
   "source": [
    "Models.append(gin)\n",
    "layers.append('GIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T14:07:58.629519Z",
     "start_time": "2022-11-05T14:07:58.615502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30.2023, 27.5369],\n",
       "        [33.6876, 30.5892],\n",
       "        [28.8655, 26.3400],\n",
       "        ...,\n",
       "        [38.3929, 35.0660],\n",
       "        [25.2044, 23.0351],\n",
       "        [25.4016, 23.1315]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T14:07:05.808468Z",
     "start_time": "2022-11-05T14:07:05.796474Z"
    }
   },
   "outputs": [],
   "source": [
    "#out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T14:06:31.887281Z",
     "start_time": "2022-11-05T14:06:31.869296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "gin.train()\n",
    "optimizer.zero_grad()\n",
    "out = gin(data.x, data.edge_index, data.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T15:08:57.337512Z",
     "start_time": "2022-11-05T15:08:55.712318Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1000x1 and 2x1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [120]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#data = data.to(device)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     F\u001b[38;5;241m.\u001b[39mnll_loss(out, data\u001b[38;5;241m.\u001b[39my)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\DataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [118]\u001b[0m, in \u001b[0;36mGIN.forward\u001b[1;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[0;32m     30\u001b[0m h3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(h2, edge_index)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#print(h3.detach().numpy().shape)\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# num_nodes x 1\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# aquí le tengo que aplicar una función para que cambie a num_nodes x num_classes\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# y ya solo regresar el softmax\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#return h3\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Graph-level readout\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\DataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\DataScience\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1000x1 and 2x1000)"
     ]
    }
   ],
   "source": [
    "#def train():\n",
    "model = gin#Models[0]\n",
    "model.train()\n",
    "\n",
    "total_loss = 0\n",
    "for data in loader:\n",
    "    #data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index, data.batch)\n",
    "    F.nll_loss(out, data.y).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:21:22.479844Z",
     "start_time": "2022-11-09T11:21:22.468577Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, data):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        F.nll_loss(model(data.x, data.edge_index), data.y).backward()\n",
    "        optimizer.step()\n",
    "        return model, optimizer\n",
    "      \n",
    "    \n",
    "@torch.no_grad()\n",
    "def test(data, model):\n",
    "  model.eval()\n",
    "  logits = model(data.x, data.edge_index)\n",
    "  pred = logits.max(1)[1]\n",
    "  acc = pred.eq(data.y).sum().item() / data.num_nodes\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:31:58.585996Z",
     "start_time": "2022-11-05T13:31:37.825430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Model:GCN -----\n",
      "Epoch 5 saved for GCN.\n",
      "\n",
      "Mean Acc: 0.8551333333333333\n",
      "\n",
      "Epoch 10 saved for GCN.\n",
      "\n",
      "Mean Acc: 0.8551333333333333\n",
      "\n",
      "Epoch 15 saved for GCN.\n",
      "\n",
      "Mean Acc: 0.8551333333333333\n",
      "\n",
      "GCN saved in runs/\n",
      "\n",
      "\n",
      " ----- Model:GAT -----\n",
      "Epoch 5 saved for GAT.\n",
      "\n",
      "Mean Acc: 0.8551333333333333\n",
      "\n",
      "Epoch 10 saved for GAT.\n",
      "\n",
      "Mean Acc: 0.8551333333333333\n",
      "\n",
      "Epoch 15 saved for GAT.\n",
      "\n",
      "Mean Acc: 0.8551333333333333\n",
      "\n",
      "GAT saved in runs/\n",
      "\n",
      "\n",
      " ----- Model:GraphConv -----\n",
      "Epoch 5 saved for GraphConv.\n",
      "\n",
      "Mean Acc: 0.14513333333333334\n",
      "\n",
      "Epoch 10 saved for GraphConv.\n",
      "\n",
      "Mean Acc: 0.14599999999999996\n",
      "\n",
      "Epoch 15 saved for GraphConv.\n",
      "\n",
      "Mean Acc: 0.1476\n",
      "\n",
      "GraphConv saved in runs/\n",
      "\n",
      "\n",
      " ----- Model:GIN -----\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m Graphs_Train:\n\u001b[1;32m---> 10\u001b[0m         \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m#torch.save(Models[i].state_dict(), f=f\"{PATH_SAVE_TRAINS_CHECKPOINTS}Checkpoint-model-{layers[i]}-epoch-{epoch}.pt\")\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayers[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, data)\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 5\u001b[0m F\u001b[38;5;241m.\u001b[39mnll_loss(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m, data\u001b[38;5;241m.\u001b[39my)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, optimizer\n",
      "File \u001b[1;32m~\\.conda\\envs\\DataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'batch'"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "for i in range(len(Models)):\n",
    "    print()\n",
    "    print(f\" ----- Model:{layers[i]} -----\")\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(Models[i].parameters(), lr = lr)\n",
    "\n",
    "    for epoch in range(1, epochs):\n",
    "        \n",
    "        for data in Graphs_Train:\n",
    "            train(Models[i], optimizer, data)\n",
    "        \n",
    "        if epoch%5 == 0:\n",
    "            #torch.save(Models[i].state_dict(), f=f\"{PATH_SAVE_TRAINS_CHECKPOINTS}Checkpoint-model-{layers[i]}-epoch-{epoch}.pt\")\n",
    "            print(f\"Epoch {epoch} saved for {layers[i]}.\\n\")\n",
    "        \n",
    "            Acc = []\n",
    "\n",
    "            for data in Graphs_Train:\n",
    "                Acc.append(test(data, Models[i]))\n",
    "            print(f\"Mean Acc: {np.mean(Acc)}\")\n",
    "            print()\n",
    "        \n",
    "    dt_string = datetime.now().strftime(\"%m-%d_%H-%M\")\n",
    "    #torch.save(Models[i].state_dict(), f=f\"{PATH_SAVE_TRAINS}{layers[i]}_seed_{SEED}_thr_{int(threshold*10)}_date_{dt_string}.pt\")\n",
    "    \n",
    "    print(f\"{layers[i]} saved in {PATH_SAVE_TRAINS}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T11:11:03.871195Z",
     "start_time": "2022-11-08T11:11:03.857192Z"
    }
   },
   "outputs": [],
   "source": [
    "#for data in Graphs_Train[0]:\n",
    "data = Graphs_Train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:21:29.329059Z",
     "start_time": "2022-11-09T11:21:29.188040Z"
    }
   },
   "outputs": [],
   "source": [
    "S = np.argsort(-np.array(nx.degree(graphs[0])).T[1])[500:]\n",
    "data = Convert2DataSet([graphs[0]], [S])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:21:29.817424Z",
     "start_time": "2022-11-09T11:21:29.804422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 9982], num_nodes=1000, x=[1000, 1], y=[1000], num_classes=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:21:31.707137Z",
     "start_time": "2022-11-09T11:21:31.691187Z"
    }
   },
   "outputs": [],
   "source": [
    "Models = [GNNModel(c_in = 1, c_hidden = 100, c_out = 2, num_layers = 1, layer_name = layer_name, dp_rate=0.3) for \n",
    "         layer_name in layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:21:50.342114Z",
     "start_time": "2022-11-09T11:21:50.331114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): GCNConv(1, 2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "optimizer = torch.optim.Adam(Models[i].parameters(), lr=0.01, weight_decay=5e-4)\n",
    "Models[i].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:22:27.932536Z",
     "start_time": "2022-11-09T11:22:27.796226Z"
    }
   },
   "outputs": [],
   "source": [
    "p = []\n",
    "for _ in range(20):\n",
    "    p.append(test(data, Models[i]))\n",
    "    train(Models[i], optimizer, data);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:21:56.131388Z",
     "start_time": "2022-11-09T11:21:56.123390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1501, -0.5032],\n",
       "        [-0.1117, -0.3746],\n",
       "        [-0.1455, -0.4879],\n",
       "        ...,\n",
       "        [-0.1181, -0.3960],\n",
       "        [-0.1053, -0.3531],\n",
       "        [-0.1635, -0.5483]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Models[i](data.x, data.edge_index)#.max(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:22:30.117187Z",
     "start_time": "2022-11-09T11:22:30.101707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:17:12.780902Z",
     "start_time": "2022-11-09T11:17:12.747965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:05:52.808863Z",
     "start_time": "2022-11-09T11:05:52.794864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5190)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:53:44.437863Z",
     "start_time": "2022-10-29T19:53:44.408207Z"
    }
   },
   "outputs": [],
   "source": [
    "import igraph\n",
    "import dgl\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from GRAT import GRAT3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import argparse\n",
    "\n",
    "\"\"\"\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"-th\", \"--Threshold\", help = \"Infection Threshold\", type = float)\n",
    "parser.add_argument(\"-type\", \"--Type\", help = \"short, large or full\", type = str)\n",
    "args = parser.parse_args()\n",
    "\"\"\"\n",
    "# Example: python EvaluateFastCover.py -th 0.5 -type \"short\"\n",
    "\n",
    "Graphs_short = [\n",
    " 'ego-facebook.txt',\n",
    " 'gemsec_facebook_artist.txt',\n",
    " 'graph_actors_dat.txt',\n",
    " 'graph_CA-AstroPh.txt',\n",
    " 'graph_CA-CondMat.txt',\n",
    " 'graph_CA-GrQc.txt',\n",
    " 'graph_CA-HepPh.txt',\n",
    " 'graph_CA-HepTh.txt',\n",
    " 'graph_dolphins.txt',\n",
    " 'graph_Email-Enron.txt',\n",
    " 'graph_football.txt',\n",
    " 'graph_jazz.txt',\n",
    " 'graph_karate.txt',\n",
    " 'graph_ncstrlwg2.txt',\n",
    " 'soc-gplus.txt',\n",
    " 'socfb-Brandeis99.txt',\n",
    " 'socfb-Mich67.txt',\n",
    " 'socfb-nips-ego.txt']\n",
    "\n",
    "Graphs_large = ['Amazon0302.txt',\n",
    " 'Amazon0312.txt',\n",
    " 'Amazon0505.txt',\n",
    " 'Amazon0601.txt',\n",
    " 'com-youtube.ungraph.txt',\n",
    " 'com-dblp.ungraph.txt',\n",
    " 'loc-gowalla_edges.txt',\n",
    " 'deezer_HR.txt',\n",
    " 'musae_git.txt']\n",
    "\n",
    "PATH_TO_TEST = \"../BRKGA/instances/txt/\"\n",
    "\"\"\"\n",
    "if args.Type == \"short\":\n",
    "    Graphs = Graphs_short\n",
    "elif args.Type == \"large\":\n",
    "    Graphs = Graphs_large\n",
    "elif args.Type == \"full\":\n",
    "    Graphs = [graph for graph in os.listdir(PATH_TO_TEST)]\n",
    "else:\n",
    "    raise NameError(\"Only: 'short', 'large' or 'full\")\n",
    "\"\"\"\n",
    "Graphs = [Graphs_short[11]]\n",
    "PATH_SAVED_TRAINS = \"runs/\"\n",
    "PATH_SAVE_RESULTS = 'results/'\n",
    "\n",
    "NAME_SAVE_RESULTS = 'Models' #Change this\n",
    "\n",
    "FEATURE_TYPE = \"1\"\n",
    "HIDDEN_FEATS = [32]*6\n",
    "input_dim = 32\n",
    "use_cuda = False\n",
    "directed_test = False\n",
    "\n",
    "#threshold = args.Threshold\n",
    "threshold = 0.5\n",
    "dt_string = datetime.now().strftime(\"%m-%d_%H-%M\")\n",
    "\n",
    "RUNS_LIST = [run for run in os.listdir(PATH_SAVED_TRAINS) if \".pt\" in run]\n",
    "\n",
    "SEEDS = []\n",
    "MODELS = []\n",
    "for run_name in RUNS_LIST:\n",
    "    SEEDS.append(run_name.split(\"_\")[2])\n",
    "    MODELS.append(run_name.split(\"_\")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:53:44.672499Z",
     "start_time": "2022-10-29T19:53:44.652734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GAT', 'GCN', 'GraphConv']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:53:59.547434Z",
     "start_time": "2022-10-29T19:53:44.943383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of model: GAT, seed: 13 in GAT_seed_13_thr_5_date_10-29_21-22.pt\n",
      "\n",
      "Loading ../BRKGA/instances/txt/graph_jazz.txt ...\n",
      "\n",
      "Starting infection\n",
      "\n",
      "0.01 Infected\n",
      "0.01 Infected\n",
      "0.02 Infected\n",
      "0.03 Infected\n",
      "0.03 Infected\n",
      "0.04 Infected\n",
      "1/1 Graph: jazz\n",
      "Best Target Set length: 54 out of 198\n",
      "Ratio Solution / Graph lentgh: 0.273\n",
      "Time: 3.67s\n",
      "\n",
      "\n",
      "Evaluation of model: GCN, seed: 13 in GCN_seed_13_thr_5_date_10-29_21-22.pt\n",
      "\n",
      "Loading ../BRKGA/instances/txt/graph_jazz.txt ...\n",
      "\n",
      "Starting infection\n",
      "\n",
      "0.01 Infected\n",
      "0.02 Infected\n",
      "0.02 Infected\n",
      "0.03 Infected\n",
      "0.03 Infected\n",
      "0.04 Infected\n",
      "1/1 Graph: jazz\n",
      "Best Target Set length: 76 out of 198\n",
      "Ratio Solution / Graph lentgh: 0.384\n",
      "Time: 7.67s\n",
      "\n",
      "\n",
      "Evaluation of model: GraphConv, seed: 13 in GraphConv_seed_13_thr_5_date_10-29_21-22.pt\n",
      "\n",
      "Loading ../BRKGA/instances/txt/graph_jazz.txt ...\n",
      "\n",
      "Starting infection\n",
      "\n",
      "0.01 Infected\n",
      "0.01 Infected\n",
      "0.02 Infected\n",
      "0.02 Infected\n",
      "0.03 Infected\n",
      "1/1 Graph: jazz\n",
      "Best Target Set length: 59 out of 198\n",
      "Ratio Solution / Graph lentgh: 0.298\n",
      "Time: 3.13s\n",
      "\n",
      "Evaluation has finnished successfully. \n",
      "Data saved in results/\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "Total = len(Graphs)\n",
    "    \n",
    "for run_name, model, seed in zip(RUNS_LIST, MODELS, SEEDS):\n",
    "    print()\n",
    "    print(f\"Evaluation of model: {model}, seed: {seed} in {run_name}\")\n",
    "    print()\n",
    "    \n",
    "    net = GNNModel(c_in = 1, c_hidden = 100, c_out = 2, num_layers = 2, layer_name = model, dp_rate=0.1)\n",
    "    net.load_state_dict(torch.load(PATH_SAVE_TRAINS+run_name))\n",
    "    \n",
    "    if use_cuda:\n",
    "        net.cuda()\n",
    "\n",
    "    c = 1\n",
    "    for file in Graphs:\n",
    "            print(f\"Loading {PATH_TO_TEST+file} ...\")\n",
    "            name = file.split(\".\")[0].replace(\"graph_\", \"\")\n",
    "\n",
    "            graph = igraph.Graph().Read_Edgelist(PATH_TO_TEST + file)\n",
    "            data = Convert2DataSet([graph.to_networkx()], [[]])[0]\n",
    "\n",
    "            #dglgraph = get_rev_dgl(graph, FEATURE_TYPE, input_dim, directed_test, use_cuda)\n",
    "            \n",
    "            print(\"\\nStarting infection\\n\")\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            out = net(data.x, data.edge_index).max(1)[0]\n",
    "\n",
    "            G = graph.to_networkx().to_undirected()\n",
    "\n",
    "            n = len(G.nodes())\n",
    "\n",
    "            _ , minTargetGRAT = FindMinimumTarget(G, out, threshold)\n",
    "\n",
    "            final_time = (time.time() - start_time)\n",
    "            print()\n",
    "            print(f\"{c}/{Total} Graph: {name}\")\n",
    "            print(f\"Best Target Set length: {minTargetGRAT} out of {n}\")\n",
    "            print(f\"Ratio Solution / Graph lentgh: {minTargetGRAT/n:.3f}\")\n",
    "            print(f\"Time: {final_time:.2f}s\")\n",
    "            print()\n",
    "            records.append({\n",
    "            \"graph\": name,\n",
    "            \"model\": model,\n",
    "            \"seed\": seed,\n",
    "            \"threshold\": threshold,\n",
    "            \"n_covered\": minTargetGRAT,\n",
    "            \"n\": n,\n",
    "            \"coverage\": minTargetGRAT/n,\n",
    "            \"t_mean\": final_time\n",
    "            })\n",
    "\n",
    "            pd.DataFrame(records).to_csv(PATH_SAVE_RESULTS + NAME_SAVE_RESULTS +\"_\" + dt_string + \".csv\")\n",
    "\n",
    "            c+=1\n",
    "print(f\"Evaluation has finnished successfully. \\nData saved in {PATH_SAVE_RESULTS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T18:21:21.707845Z",
     "start_time": "2022-10-22T18:21:21.672912Z"
    }
   },
   "outputs": [],
   "source": [
    "Models = [GNNModel(c_in = 1, c_hidden = 100, c_out = 2, num_layers = 2, layer_name = layer_name, dp_rate=0.1) for \n",
    "         layer_name in layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:30:22.167984Z",
     "start_time": "2022-10-29T19:30:22.147311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs/GraphConv_seed_13_thr_5_date_10-29_21-22.pt'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_SAVE_TRAINS+run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:37:33.611736Z",
     "start_time": "2022-10-29T19:37:33.547436Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convert2DataSet(Graphs, Optimals)\n",
    "D = Convert2DataSet([graph.to_networkx()], [[]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:44:02.116995Z",
     "start_time": "2022-10-29T19:43:16.182996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting infection\n",
      "\n",
      "0.00 Infected\n",
      "0.00 Infected\n",
      "0.00 Infected\n",
      "0.00 Infected\n",
      "0.01 Infected\n",
      "0.01 Infected\n"
     ]
    }
   ],
   "source": [
    "#graph = igraph.Graph().Read_Edgelist(PATH_TO_TEST + file)\n",
    "data = Convert2DataSet([graph.to_networkx()], [[]])[0]\n",
    "\n",
    "#dglgraph = get_rev_dgl(graph, FEATURE_TYPE, input_dim, directed_test, use_cuda)\n",
    "\n",
    "print(\"\\nStarting infection\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "out = net(data.x, data.edge_index).max(1)[0]\n",
    "\n",
    "G = graph.to_networkx().to_undirected()\n",
    "\n",
    "n = len(G.nodes())\n",
    "\n",
    "_ , minTargetGRAT = FindMinimumTarget(G, out, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:54:39.183780Z",
     "start_time": "2022-11-05T13:54:38.997964Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset DATASET] [--batch_size BATCH_SIZE] [--hidden_channels HIDDEN_CHANNELS]\n",
      "                             [--num_layers NUM_LAYERS] [--lr LR] [--epochs EPOCHS] [--wandb]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Jairo Enrique\\AppData\\Roaming\\jupyter\\runtime\\kernel-14a63839-b6dc-474c-abba-b24691ef990f.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jairo Enrique\\.conda\\envs\\DataScience\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
