{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:27:42.786999Z",
     "start_time": "2022-11-05T13:27:40.486605Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "#from create_dataset import CreateDataset\n",
    "\n",
    "from models import GNNModel\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FastCover/\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:27:42.845566Z",
     "start_time": "2022-11-05T13:27:42.819582Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_SAVE_TRAINS_CHECKPOINTS = 'runs/checkpoints/'\n",
    "PATH_SAVE_TRAINS = 'runs/'\n",
    "PATH_TRAIN = '../FastCover/data/ER_graphs/train/'\n",
    "\n",
    "num_features = 1\n",
    "num_classes  = 2\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "optimizer_name = \"Adam\"\n",
    "lr = 1e-3\n",
    "epochs = 20\n",
    "\n",
    "SEED = 13\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "layers = [\"GCN\", \"GAT\",\"GraphConv\"]\n",
    "\n",
    "Models = [GNNModel(c_in = 1, c_hidden = 100, c_out = 2, num_layers = 2, layer_name = layer_name, dp_rate=0.1) for \n",
    "         layer_name in layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:28:40.725329Z",
     "start_time": "2022-11-05T13:28:40.219040Z"
    }
   },
   "outputs": [],
   "source": [
    "ERInstances = [graph for graph in os.listdir(PATH_TRAIN+'pkl')]\n",
    "graphs = []\n",
    "for er in ERInstances:\n",
    "    graph = igraph.Graph().Read_Pickle(PATH_TRAIN + 'pkl/'+er)\n",
    "    graphs.append(graph.to_networkx())    \n",
    "\n",
    "OptInstances = [graph for graph in os.listdir(PATH_TRAIN+'optimal')]\n",
    "Solutions = []\n",
    "for er in OptInstances:\n",
    "    opt = []\n",
    "    with open(PATH_TRAIN+'optimal/'+er) as f:\n",
    "        for line in f.readlines():\n",
    "            opt.append(int(line.replace(\"\\n\", \"\")))\n",
    "    Solutions.append(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T20:44:36.042090Z",
     "start_time": "2022-10-29T20:44:36.034117Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:21:57.430612Z",
     "start_time": "2022-10-29T19:21:57.418818Z"
    }
   },
   "outputs": [],
   "source": [
    "## Falta por incluir estax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T15:08:51.042988Z",
     "start_time": "2022-11-05T15:08:51.012990Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    \"\"\"GIN\"\"\"\n",
    "    def __init__(self, dim_h, num_features, num_classes):\n",
    "        super(GIN, self).__init__()\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(num_features, dim_h),\n",
    "                       BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        \n",
    "        self.lin1 = Linear(dim_h*3, dim_h*3)\n",
    "        self.lin2 = Linear(dim_h*3, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Node embeddings \n",
    "        h1 = self.conv1(x, edge_index)\n",
    "        h2 = self.conv2(h1, edge_index)\n",
    "        h3 = self.conv3(h2, edge_index)\n",
    "        #print(h3.detach().numpy().shape)\n",
    "        x = Linear(2, 1000)(h3)\n",
    "        print(x.detach().numpy().shape)\n",
    "        # num_nodes x 1\n",
    "        # aquí le tengo que aplicar una función para que cambie a num_nodes x num_classes\n",
    "        # y ya solo regresar el softmax\n",
    "        #return h3\n",
    "\n",
    "        # Graph-level readout\n",
    "        h1 = global_add_pool(h1, batch)\n",
    "        h2 = global_add_pool(h2, batch)\n",
    "        h3 = global_add_pool(h3, batch)\n",
    "        # 1 x 1 due to global pooling\n",
    "        \n",
    "        print(h3.detach().numpy().shape)\n",
    "\n",
    "        # Concatenate graph embeddings\n",
    "        h = torch.cat((h1, h2, h3), dim=1)\n",
    "        #3x1 due to concat\n",
    "\n",
    "        # Classifier\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        #3 x num_classes due to \n",
    "        \n",
    "        return h, F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:47:35.044720Z",
     "start_time": "2022-11-05T13:47:35.035769Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:53:10.263795Z",
     "start_time": "2022-11-05T13:53:10.250744Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(Graphs_Train, batch_size=1)\n",
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:53:10.955578Z",
     "start_time": "2022-11-05T13:53:10.949577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 9982], num_nodes=1000, x=[1000, 1], y=[1000], num_classes=[1], batch=[1000], ptr=[2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:31:02.141697Z",
     "start_time": "2022-11-05T13:31:01.989668Z"
    }
   },
   "outputs": [],
   "source": [
    "Graphs_Train = Convert2DataSet(graphs, Solutions)\n",
    "num_features = Graphs_Train[0].num_features\n",
    "num_classes = Graphs_Train[0].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T15:08:53.442190Z",
     "start_time": "2022-11-05T15:08:53.422193Z"
    }
   },
   "outputs": [],
   "source": [
    "gin = GIN(dim_h = 1, num_classes = num_classes, num_features = num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:31:17.209075Z",
     "start_time": "2022-11-05T13:31:17.201075Z"
    }
   },
   "outputs": [],
   "source": [
    "Models.append(gin)\n",
    "layers.append('GIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T14:07:58.629519Z",
     "start_time": "2022-11-05T14:07:58.615502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30.2023, 27.5369],\n",
       "        [33.6876, 30.5892],\n",
       "        [28.8655, 26.3400],\n",
       "        ...,\n",
       "        [38.3929, 35.0660],\n",
       "        [25.2044, 23.0351],\n",
       "        [25.4016, 23.1315]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T14:07:05.808468Z",
     "start_time": "2022-11-05T14:07:05.796474Z"
    }
   },
   "outputs": [],
   "source": [
    "#out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T14:06:31.887281Z",
     "start_time": "2022-11-05T14:06:31.869296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "gin.train()\n",
    "optimizer.zero_grad()\n",
    "out = gin(data.x, data.edge_index, data.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T15:08:57.337512Z",
     "start_time": "2022-11-05T15:08:55.712318Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1000x1 and 2x1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [120]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#data = data.to(device)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     F\u001b[38;5;241m.\u001b[39mnll_loss(out, data\u001b[38;5;241m.\u001b[39my)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\DataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [118]\u001b[0m, in \u001b[0;36mGIN.forward\u001b[1;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[0;32m     30\u001b[0m h3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(h2, edge_index)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#print(h3.detach().numpy().shape)\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# num_nodes x 1\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# aquí le tengo que aplicar una función para que cambie a num_nodes x num_classes\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# y ya solo regresar el softmax\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#return h3\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Graph-level readout\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\DataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\.conda\\envs\\DataScience\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1000x1 and 2x1000)"
     ]
    }
   ],
   "source": [
    "#def train():\n",
    "model = gin#Models[0]\n",
    "model.train()\n",
    "\n",
    "total_loss = 0\n",
    "for data in loader:\n",
    "    #data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index, data.batch)\n",
    "    F.nll_loss(out, data.y).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:31:20.102017Z",
     "start_time": "2022-11-05T13:31:20.085012Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, data):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        F.nll_loss(model(data.x, data.edge_index), data.y).backward()\n",
    "        optimizer.step()\n",
    "        return model, optimizer\n",
    "      \n",
    "    \n",
    "@torch.no_grad()\n",
    "def test(data, model):\n",
    "  model.eval()\n",
    "  logits = model(data.x, data.edge_index)\n",
    "  pred = logits.max(1)[1]\n",
    "  acc = pred.eq(data.y).sum().item() / data.num_nodes\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:31:58.585996Z",
     "start_time": "2022-11-05T13:31:37.825430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Model:GCN -----\n",
      "Epoch 5 saved for GCN.\n",
      "\n",
      "Mean Acc: 0.8551333333333333\n",
      "\n",
      "Epoch 10 saved for GCN.\n",
      "\n",
      "Mean Acc: 0.8551333333333333\n",
      "\n",
      "Epoch 15 saved for GCN.\n",
      "\n",
      "Mean Acc: 0.8551333333333333\n",
      "\n",
      "GCN saved in runs/\n",
      "\n",
      "\n",
      " ----- Model:GAT -----\n",
      "Epoch 5 saved for GAT.\n",
      "\n",
      "Mean Acc: 0.8551333333333333\n",
      "\n",
      "Epoch 10 saved for GAT.\n",
      "\n",
      "Mean Acc: 0.8551333333333333\n",
      "\n",
      "Epoch 15 saved for GAT.\n",
      "\n",
      "Mean Acc: 0.8551333333333333\n",
      "\n",
      "GAT saved in runs/\n",
      "\n",
      "\n",
      " ----- Model:GraphConv -----\n",
      "Epoch 5 saved for GraphConv.\n",
      "\n",
      "Mean Acc: 0.14513333333333334\n",
      "\n",
      "Epoch 10 saved for GraphConv.\n",
      "\n",
      "Mean Acc: 0.14599999999999996\n",
      "\n",
      "Epoch 15 saved for GraphConv.\n",
      "\n",
      "Mean Acc: 0.1476\n",
      "\n",
      "GraphConv saved in runs/\n",
      "\n",
      "\n",
      " ----- Model:GIN -----\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m Graphs_Train:\n\u001b[1;32m---> 10\u001b[0m         \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m#torch.save(Models[i].state_dict(), f=f\"{PATH_SAVE_TRAINS_CHECKPOINTS}Checkpoint-model-{layers[i]}-epoch-{epoch}.pt\")\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayers[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, data)\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 5\u001b[0m F\u001b[38;5;241m.\u001b[39mnll_loss(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m, data\u001b[38;5;241m.\u001b[39my)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, optimizer\n",
      "File \u001b[1;32m~\\.conda\\envs\\DataScience\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'batch'"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "for i in range(len(Models)):\n",
    "    print()\n",
    "    print(f\" ----- Model:{layers[i]} -----\")\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(Models[i].parameters(), lr = lr)\n",
    "\n",
    "    for epoch in range(1, epochs):\n",
    "        \n",
    "        for data in Graphs_Train:\n",
    "            train(Models[i], optimizer, data)\n",
    "        \n",
    "        if epoch%5 == 0:\n",
    "            #torch.save(Models[i].state_dict(), f=f\"{PATH_SAVE_TRAINS_CHECKPOINTS}Checkpoint-model-{layers[i]}-epoch-{epoch}.pt\")\n",
    "            print(f\"Epoch {epoch} saved for {layers[i]}.\\n\")\n",
    "        \n",
    "            Acc = []\n",
    "\n",
    "            for data in Graphs_Train:\n",
    "                Acc.append(test(data, Models[i]))\n",
    "            print(f\"Mean Acc: {np.mean(Acc)}\")\n",
    "            print()\n",
    "        \n",
    "    dt_string = datetime.now().strftime(\"%m-%d_%H-%M\")\n",
    "    #torch.save(Models[i].state_dict(), f=f\"{PATH_SAVE_TRAINS}{layers[i]}_seed_{SEED}_thr_{int(threshold*10)}_date_{dt_string}.pt\")\n",
    "    \n",
    "    print(f\"{layers[i]} saved in {PATH_SAVE_TRAINS}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:53:44.437863Z",
     "start_time": "2022-10-29T19:53:44.408207Z"
    }
   },
   "outputs": [],
   "source": [
    "import igraph\n",
    "import dgl\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from GRAT import GRAT3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import argparse\n",
    "\n",
    "\"\"\"\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"-th\", \"--Threshold\", help = \"Infection Threshold\", type = float)\n",
    "parser.add_argument(\"-type\", \"--Type\", help = \"short, large or full\", type = str)\n",
    "args = parser.parse_args()\n",
    "\"\"\"\n",
    "# Example: python EvaluateFastCover.py -th 0.5 -type \"short\"\n",
    "\n",
    "Graphs_short = [\n",
    " 'ego-facebook.txt',\n",
    " 'gemsec_facebook_artist.txt',\n",
    " 'graph_actors_dat.txt',\n",
    " 'graph_CA-AstroPh.txt',\n",
    " 'graph_CA-CondMat.txt',\n",
    " 'graph_CA-GrQc.txt',\n",
    " 'graph_CA-HepPh.txt',\n",
    " 'graph_CA-HepTh.txt',\n",
    " 'graph_dolphins.txt',\n",
    " 'graph_Email-Enron.txt',\n",
    " 'graph_football.txt',\n",
    " 'graph_jazz.txt',\n",
    " 'graph_karate.txt',\n",
    " 'graph_ncstrlwg2.txt',\n",
    " 'soc-gplus.txt',\n",
    " 'socfb-Brandeis99.txt',\n",
    " 'socfb-Mich67.txt',\n",
    " 'socfb-nips-ego.txt']\n",
    "\n",
    "Graphs_large = ['Amazon0302.txt',\n",
    " 'Amazon0312.txt',\n",
    " 'Amazon0505.txt',\n",
    " 'Amazon0601.txt',\n",
    " 'com-youtube.ungraph.txt',\n",
    " 'com-dblp.ungraph.txt',\n",
    " 'loc-gowalla_edges.txt',\n",
    " 'deezer_HR.txt',\n",
    " 'musae_git.txt']\n",
    "\n",
    "PATH_TO_TEST = \"../BRKGA/instances/txt/\"\n",
    "\"\"\"\n",
    "if args.Type == \"short\":\n",
    "    Graphs = Graphs_short\n",
    "elif args.Type == \"large\":\n",
    "    Graphs = Graphs_large\n",
    "elif args.Type == \"full\":\n",
    "    Graphs = [graph for graph in os.listdir(PATH_TO_TEST)]\n",
    "else:\n",
    "    raise NameError(\"Only: 'short', 'large' or 'full\")\n",
    "\"\"\"\n",
    "Graphs = [Graphs_short[11]]\n",
    "PATH_SAVED_TRAINS = \"runs/\"\n",
    "PATH_SAVE_RESULTS = 'results/'\n",
    "\n",
    "NAME_SAVE_RESULTS = 'Models' #Change this\n",
    "\n",
    "FEATURE_TYPE = \"1\"\n",
    "HIDDEN_FEATS = [32]*6\n",
    "input_dim = 32\n",
    "use_cuda = False\n",
    "directed_test = False\n",
    "\n",
    "#threshold = args.Threshold\n",
    "threshold = 0.5\n",
    "dt_string = datetime.now().strftime(\"%m-%d_%H-%M\")\n",
    "\n",
    "RUNS_LIST = [run for run in os.listdir(PATH_SAVED_TRAINS) if \".pt\" in run]\n",
    "\n",
    "SEEDS = []\n",
    "MODELS = []\n",
    "for run_name in RUNS_LIST:\n",
    "    SEEDS.append(run_name.split(\"_\")[2])\n",
    "    MODELS.append(run_name.split(\"_\")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:53:44.672499Z",
     "start_time": "2022-10-29T19:53:44.652734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GAT', 'GCN', 'GraphConv']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:53:59.547434Z",
     "start_time": "2022-10-29T19:53:44.943383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of model: GAT, seed: 13 in GAT_seed_13_thr_5_date_10-29_21-22.pt\n",
      "\n",
      "Loading ../BRKGA/instances/txt/graph_jazz.txt ...\n",
      "\n",
      "Starting infection\n",
      "\n",
      "0.01 Infected\n",
      "0.01 Infected\n",
      "0.02 Infected\n",
      "0.03 Infected\n",
      "0.03 Infected\n",
      "0.04 Infected\n",
      "1/1 Graph: jazz\n",
      "Best Target Set length: 54 out of 198\n",
      "Ratio Solution / Graph lentgh: 0.273\n",
      "Time: 3.67s\n",
      "\n",
      "\n",
      "Evaluation of model: GCN, seed: 13 in GCN_seed_13_thr_5_date_10-29_21-22.pt\n",
      "\n",
      "Loading ../BRKGA/instances/txt/graph_jazz.txt ...\n",
      "\n",
      "Starting infection\n",
      "\n",
      "0.01 Infected\n",
      "0.02 Infected\n",
      "0.02 Infected\n",
      "0.03 Infected\n",
      "0.03 Infected\n",
      "0.04 Infected\n",
      "1/1 Graph: jazz\n",
      "Best Target Set length: 76 out of 198\n",
      "Ratio Solution / Graph lentgh: 0.384\n",
      "Time: 7.67s\n",
      "\n",
      "\n",
      "Evaluation of model: GraphConv, seed: 13 in GraphConv_seed_13_thr_5_date_10-29_21-22.pt\n",
      "\n",
      "Loading ../BRKGA/instances/txt/graph_jazz.txt ...\n",
      "\n",
      "Starting infection\n",
      "\n",
      "0.01 Infected\n",
      "0.01 Infected\n",
      "0.02 Infected\n",
      "0.02 Infected\n",
      "0.03 Infected\n",
      "1/1 Graph: jazz\n",
      "Best Target Set length: 59 out of 198\n",
      "Ratio Solution / Graph lentgh: 0.298\n",
      "Time: 3.13s\n",
      "\n",
      "Evaluation has finnished successfully. \n",
      "Data saved in results/\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "Total = len(Graphs)\n",
    "    \n",
    "for run_name, model, seed in zip(RUNS_LIST, MODELS, SEEDS):\n",
    "    print()\n",
    "    print(f\"Evaluation of model: {model}, seed: {seed} in {run_name}\")\n",
    "    print()\n",
    "    \n",
    "    net = GNNModel(c_in = 1, c_hidden = 100, c_out = 2, num_layers = 2, layer_name = model, dp_rate=0.1)\n",
    "    net.load_state_dict(torch.load(PATH_SAVE_TRAINS+run_name))\n",
    "    \n",
    "    if use_cuda:\n",
    "        net.cuda()\n",
    "\n",
    "    c = 1\n",
    "    for file in Graphs:\n",
    "            print(f\"Loading {PATH_TO_TEST+file} ...\")\n",
    "            name = file.split(\".\")[0].replace(\"graph_\", \"\")\n",
    "\n",
    "            graph = igraph.Graph().Read_Edgelist(PATH_TO_TEST + file)\n",
    "            data = Convert2DataSet([graph.to_networkx()], [[]])[0]\n",
    "\n",
    "            #dglgraph = get_rev_dgl(graph, FEATURE_TYPE, input_dim, directed_test, use_cuda)\n",
    "            \n",
    "            print(\"\\nStarting infection\\n\")\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            out = net(data.x, data.edge_index).max(1)[0]\n",
    "\n",
    "            G = graph.to_networkx().to_undirected()\n",
    "\n",
    "            n = len(G.nodes())\n",
    "\n",
    "            _ , minTargetGRAT = FindMinimumTarget(G, out, threshold)\n",
    "\n",
    "            final_time = (time.time() - start_time)\n",
    "            print()\n",
    "            print(f\"{c}/{Total} Graph: {name}\")\n",
    "            print(f\"Best Target Set length: {minTargetGRAT} out of {n}\")\n",
    "            print(f\"Ratio Solution / Graph lentgh: {minTargetGRAT/n:.3f}\")\n",
    "            print(f\"Time: {final_time:.2f}s\")\n",
    "            print()\n",
    "            records.append({\n",
    "            \"graph\": name,\n",
    "            \"model\": model,\n",
    "            \"seed\": seed,\n",
    "            \"threshold\": threshold,\n",
    "            \"n_covered\": minTargetGRAT,\n",
    "            \"n\": n,\n",
    "            \"coverage\": minTargetGRAT/n,\n",
    "            \"t_mean\": final_time\n",
    "            })\n",
    "\n",
    "            pd.DataFrame(records).to_csv(PATH_SAVE_RESULTS + NAME_SAVE_RESULTS +\"_\" + dt_string + \".csv\")\n",
    "\n",
    "            c+=1\n",
    "print(f\"Evaluation has finnished successfully. \\nData saved in {PATH_SAVE_RESULTS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T18:21:21.707845Z",
     "start_time": "2022-10-22T18:21:21.672912Z"
    }
   },
   "outputs": [],
   "source": [
    "Models = [GNNModel(c_in = 1, c_hidden = 100, c_out = 2, num_layers = 2, layer_name = layer_name, dp_rate=0.1) for \n",
    "         layer_name in layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:30:22.167984Z",
     "start_time": "2022-10-29T19:30:22.147311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs/GraphConv_seed_13_thr_5_date_10-29_21-22.pt'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_SAVE_TRAINS+run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:37:33.611736Z",
     "start_time": "2022-10-29T19:37:33.547436Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convert2DataSet(Graphs, Optimals)\n",
    "D = Convert2DataSet([graph.to_networkx()], [[]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-29T19:44:02.116995Z",
     "start_time": "2022-10-29T19:43:16.182996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting infection\n",
      "\n",
      "0.00 Infected\n",
      "0.00 Infected\n",
      "0.00 Infected\n",
      "0.00 Infected\n",
      "0.01 Infected\n",
      "0.01 Infected\n"
     ]
    }
   ],
   "source": [
    "#graph = igraph.Graph().Read_Edgelist(PATH_TO_TEST + file)\n",
    "data = Convert2DataSet([graph.to_networkx()], [[]])[0]\n",
    "\n",
    "#dglgraph = get_rev_dgl(graph, FEATURE_TYPE, input_dim, directed_test, use_cuda)\n",
    "\n",
    "print(\"\\nStarting infection\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "out = net(data.x, data.edge_index).max(1)[0]\n",
    "\n",
    "G = graph.to_networkx().to_undirected()\n",
    "\n",
    "n = len(G.nodes())\n",
    "\n",
    "_ , minTargetGRAT = FindMinimumTarget(G, out, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-05T13:54:39.183780Z",
     "start_time": "2022-11-05T13:54:38.997964Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset DATASET] [--batch_size BATCH_SIZE] [--hidden_channels HIDDEN_CHANNELS]\n",
      "                             [--num_layers NUM_LAYERS] [--lr LR] [--epochs EPOCHS] [--wandb]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Jairo Enrique\\AppData\\Roaming\\jupyter\\runtime\\kernel-14a63839-b6dc-474c-abba-b24691ef990f.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jairo Enrique\\.conda\\envs\\DataScience\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
