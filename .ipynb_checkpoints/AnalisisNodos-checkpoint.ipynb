{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e39103b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T15:07:04.297292Z",
     "start_time": "2022-12-17T15:06:50.485470Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch_geometric.nn as geom_nn\n",
    "import matplotlib.pyplot as plt\n",
    "from icecream import ic\n",
    "import sys\n",
    "\n",
    "ic.configureOutput(\"debug | -> \")\n",
    "\n",
    "import pandas as pd\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "sys.path.append(\"Models/\")\n",
    "from models import GNN\n",
    "\n",
    "sys.path.append(\"FastCover/\")\n",
    "\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5c7090a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T13:21:43.132921Z",
     "start_time": "2022-12-17T13:21:43.121711Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_TRAIN = \"BRKGA/instances/Erdos/train/\"\n",
    "#PATH_TO_TRAIN = \"BRKGA/instances/scalefree/train/\"\n",
    "epochs = 30\n",
    "seed = 22\n",
    "\n",
    "#v.g. python TrainModels.py -pi \"../BRKGA/instances/Erdos/train/\" -ps \"runs/Erdos/\" -MDH 0 -s 13 -e 31 -pv \"\"\n",
    "\n",
    "PATH_SAVE_TRAINS = 'Models/runs/Erdos/'\n",
    "#PATH_TO_TRAIN = \"../BRKGA/instances/Erdos/train/\"\n",
    "\n",
    "num_features = 4 # Change if needed\n",
    "    \n",
    "num_classes = 2\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "optimizer_name = \"Adam\"\n",
    "lr = 5e-4\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "layers = [\"GCN\", \"GAT\",\"GraphConv\", \"SAGE\"]\n",
    "#layers = [\"SAGE\"]\n",
    "    \n",
    "Models = [GNN(num_features, num_classes, name_layer = layer_name) for \n",
    "         layer_name in layers]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "272b70eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T13:21:48.740895Z",
     "start_time": "2022-12-17T13:21:44.382602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cargando Features...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Instances = [graph for graph in os.listdir(PATH_TO_TRAIN + 'txt')]\n",
    "\n",
    "graphs = []\n",
    "for er in Instances:\n",
    "    graph = igraph.Graph.Read_Edgelist(PATH_TO_TRAIN+\"txt/\"+er, directed = False)\n",
    "    graphs.append(graph.to_networkx())    \n",
    "\n",
    "OptInstances = [graph for graph in os.listdir(PATH_TO_TRAIN+'optimal')]\n",
    "Solutions = []\n",
    "for er in OptInstances:\n",
    "    opt = []\n",
    "    with open(PATH_TO_TRAIN+'optimal/'+er) as f:\n",
    "        for line in f.readlines():\n",
    "            opt.append(int(line.replace(\"\\n\", \"\")))\n",
    "    Solutions.append(opt)   \n",
    "\n",
    "\n",
    "print(\"\\nCargando Features...\\n\")\n",
    "graphFeatures = [feat for feat in os.listdir(PATH_TO_TRAIN+'feats')]\n",
    "Features = []\n",
    "for er in graphFeatures:\n",
    "    temp = []\n",
    "    try:\n",
    "        with open(PATH_TO_TRAIN+'feats/'+er) as f:\n",
    "            c = 0\n",
    "\n",
    "            for line in f.readlines()[1:]:\n",
    "                c+=1\n",
    "                feats = np.array(line.split(\",\"), dtype = float)\n",
    "                temp.append(feats)\n",
    "        temp = np.array(temp)\n",
    "        #temp = np.delete(temp, 2, 1)\n",
    "        Features.append(temp)\n",
    "    except:\n",
    "        print(er)\n",
    "        print(line)\n",
    "        print(c)\n",
    "    \n",
    "Graphs_Train = Convert2DataSet(graphs, Solutions, feats = Features)\n",
    "\n",
    "num_features = Graphs_Train[0].num_features\n",
    "num_classes = Graphs_Train[0].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "794dbb6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T13:21:50.920729Z",
     "start_time": "2022-12-17T13:21:50.907123Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch_geometric.nn import Linear\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes, name_layer = \"SAGE\"):\n",
    "        super().__init__()\n",
    "        self.name = name_layer\n",
    "        layer = None\n",
    "        hidden_feats = 64\n",
    "        \n",
    "        if name_layer == \"SAGE\":\n",
    "            layer = geom_nn.SAGEConv\n",
    "            \n",
    "            self.conv1 = layer(num_node_features, hidden_feats)\n",
    "            self.conv3 = Linear(hidden_feats, num_classes)\n",
    "            \n",
    "        elif name_layer == \"GAT\":\n",
    "            layer = geom_nn.GATConv\n",
    "            \n",
    "            self.conv1 = layer(num_node_features, hidden_feats)\n",
    "            self.conv3 = Linear(hidden_feats, num_classes)\n",
    "            \n",
    "        elif name_layer == \"GCN\":\n",
    "            layer = geom_nn.GCNConv\n",
    "            \n",
    "            self.conv1 = layer(num_node_features, num_classes)\n",
    "            #self.conv1 = layer(num_node_features, hidden_feats)\n",
    "            #self.conv3 = Linear(hidden_feats, num_classes)\n",
    "            \n",
    "        elif name_layer == \"GraphConv\":\n",
    "            layer = geom_nn.GraphConv\n",
    "            \n",
    "            self.conv1 = layer(num_node_features, num_classes)\n",
    "            \n",
    "        elif name_layer == \"SGConv\":\n",
    "            layer = geom_nn.SGConv\n",
    "            \n",
    "            self.conv1 = layer(num_node_features, hidden_feats)\n",
    "            self.conv3 = Linear(hidden_feats, num_classes)\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            print(\"Nanais\")\n",
    "    \n",
    "        \n",
    "        #self.conv2 = layer(hidden_feats, hidden_feats)\n",
    "        #self.conv3 = Linear(hidden_feats, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        #x = self.conv2(x, edge_index)\n",
    "\n",
    "        #return F.log_softmax(self.conv3(x), dim=1)\n",
    "        if self.name in ['GraphConv', 'GCN']:\n",
    "            return F.log_softmax(x, dim=1)\n",
    "        else:\n",
    "            return F.log_softmax(self.conv3(x), dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42a02bfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T13:21:52.912796Z",
     "start_time": "2022-12-17T13:21:52.900097Z"
    }
   },
   "outputs": [],
   "source": [
    "layers = [\"GCN\", \"GAT\",\"GraphConv\", \"SAGE\", \"SGConv\"]\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "Models = [GNN(num_features, num_classes, name_layer = layer_name) for \n",
    "         layer_name in layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b160814",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T13:29:00.106235Z",
     "start_time": "2022-12-17T13:21:55.102841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probando GCN\n",
      "Epoch 0 - Loss: 0.71 - Mean Acc 0.14 - MDH 0.16 - Acc Norm 0.522 - AccNaive 0.817\n",
      "Epoch 20 - Loss: 0.48 - Mean Acc 0.14 - MDH 0.16 - Acc Norm 0.875 - AccNaive 0.817\n",
      "Epoch 40 - Loss: 0.43 - Mean Acc 0.14 - MDH 0.16 - Acc Norm 0.860 - AccNaive 0.817\n",
      "Epoch 60 - Loss: 0.41 - Mean Acc 0.14 - MDH 0.16 - Acc Norm 0.852 - AccNaive 0.817\n",
      "Epoch 80 - Loss: 0.39 - Mean Acc 0.14 - MDH 0.16 - Acc Norm 0.853 - AccNaive 0.817\n",
      "\n",
      "Final Epoch - Best Loss: 0.38 - Best Acc 0.14 - MDH 0.16 - Best Acc Norm 0.856 - AccNaive 0.817\n",
      "\n",
      "Probando GAT\n",
      "Epoch 0 - Loss: 0.67 - Mean Acc 0.05 - MDH 0.16 - Acc Norm 0.817 - AccNaive 0.817\n",
      "Epoch 20 - Loss: 0.67 - Mean Acc 0.06 - MDH 0.16 - Acc Norm 0.668 - AccNaive 0.817\n",
      "Epoch 40 - Loss: 0.72 - Mean Acc 0.06 - MDH 0.16 - Acc Norm 0.686 - AccNaive 0.817\n",
      "Epoch 60 - Loss: 0.72 - Mean Acc 0.06 - MDH 0.16 - Acc Norm 0.705 - AccNaive 0.817\n",
      "Epoch 80 - Loss: 0.67 - Mean Acc 0.10 - MDH 0.16 - Acc Norm 0.753 - AccNaive 0.817\n",
      "\n",
      "Final Epoch - Best Loss: 0.66 - Best Acc 0.06 - MDH 0.16 - Best Acc Norm 0.701 - AccNaive 0.817\n",
      "\n",
      "Probando GraphConv\n",
      "Epoch 0 - Loss: 0.75 - Mean Acc 0.06 - MDH 0.16 - Acc Norm 0.555 - AccNaive 0.817\n",
      "Epoch 20 - Loss: 0.40 - Mean Acc 0.15 - MDH 0.16 - Acc Norm 0.876 - AccNaive 0.817\n",
      "Epoch 40 - Loss: 0.36 - Mean Acc 0.15 - MDH 0.16 - Acc Norm 0.888 - AccNaive 0.817\n",
      "Epoch 60 - Loss: 0.35 - Mean Acc 0.15 - MDH 0.16 - Acc Norm 0.891 - AccNaive 0.817\n",
      "Epoch 80 - Loss: 0.35 - Mean Acc 0.15 - MDH 0.16 - Acc Norm 0.891 - AccNaive 0.817\n",
      "\n",
      "Final Epoch - Best Loss: 0.35 - Best Acc 0.15 - MDH 0.16 - Best Acc Norm 0.891 - AccNaive 0.817\n",
      "\n",
      "Probando SAGE\n",
      "Epoch 0 - Loss: 0.45 - Mean Acc 0.16 - MDH 0.16 - Acc Norm 0.884 - AccNaive 0.817\n",
      "Epoch 20 - Loss: 0.26 - Mean Acc 0.16 - MDH 0.16 - Acc Norm 0.911 - AccNaive 0.817\n",
      "Epoch 40 - Loss: 0.25 - Mean Acc 0.16 - MDH 0.16 - Acc Norm 0.912 - AccNaive 0.817\n",
      "Epoch 60 - Loss: 0.25 - Mean Acc 0.16 - MDH 0.16 - Acc Norm 0.913 - AccNaive 0.817\n",
      "Epoch 80 - Loss: 0.25 - Mean Acc 0.16 - MDH 0.16 - Acc Norm 0.911 - AccNaive 0.817\n",
      "\n",
      "Final Epoch - Best Loss: 0.24 - Best Acc 0.16 - MDH 0.16 - Best Acc Norm 0.913 - AccNaive 0.817\n",
      "\n",
      "Probando SGConv\n",
      "Epoch 0 - Loss: 0.61 - Mean Acc 0.13 - MDH 0.16 - Acc Norm 0.842 - AccNaive 0.817\n",
      "Epoch 20 - Loss: 0.44 - Mean Acc 0.14 - MDH 0.16 - Acc Norm 0.870 - AccNaive 0.817\n",
      "Epoch 40 - Loss: 0.44 - Mean Acc 0.14 - MDH 0.16 - Acc Norm 0.870 - AccNaive 0.817\n",
      "Epoch 60 - Loss: 0.44 - Mean Acc 0.14 - MDH 0.16 - Acc Norm 0.870 - AccNaive 0.817\n",
      "Epoch 80 - Loss: 0.44 - Mean Acc 0.14 - MDH 0.16 - Acc Norm 0.871 - AccNaive 0.817\n",
      "\n",
      "Final Epoch - Best Loss: 0.44 - Best Acc 0.14 - MDH 0.16 - Best Acc Norm 0.859 - AccNaive 0.817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "dt_string = datetime.now().strftime(\"%m-%d_%H-%M\")\n",
    "\n",
    "weights = [1, 3]\n",
    "class_weights = torch.FloatTensor(weights).cpu()\n",
    "\n",
    "for i in range(len(layers)):\n",
    "    print(f\"Probando {layers[i]}\")\n",
    "    \n",
    "        \n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    Models[i] = Models[i].to(device)\n",
    "    \n",
    "    minloss = np.inf\n",
    "    bestacc = None\n",
    "    bestaccnorm = None\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        EpochAcc = []\n",
    "        EpochNorm = []\n",
    "        EpochNaive = []\n",
    "        EpochLoss = []\n",
    "        EpochMDH = []\n",
    "        for ig, data in enumerate(Graphs_Train):\n",
    "\n",
    "\n",
    "            data = data.to(device)\n",
    "            optimizer = torch.optim.Adam(Models[i].parameters(), lr=0.01, weight_decay= 0)\n",
    "\n",
    "            y = data.y.detach().numpy().copy()\n",
    "\n",
    "            Models[i].train()\n",
    "            optimizer.zero_grad()\n",
    "            out = Models[i](data)\n",
    "            loss = F.nll_loss(out, data.y, weight = class_weights)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            y_pred = torch.exp(Models[i](data)).T[1]\n",
    "            y_pred_new = np.sort(torch.topk(y_pred, int(sum(y)))[1].detach().numpy())\n",
    "\n",
    "            val = len(np.intersect1d(np.where(y == 1)[0], y_pred_new)) / len(y)\n",
    "            \n",
    "            y_mdh = torch.topk( torch.tensor(np.array(list(dict(nx.degree(graphs[ig])).values()))) , int(sum(y)))[1].detach().numpy()\n",
    "            mdh = len(np.intersect1d(np.where(y == 1)[0], y_mdh)) / len(y)\n",
    "            \n",
    "            EpochAcc.append(val)\n",
    "            EpochLoss.append(float(loss))\n",
    "            EpochMDH.append(mdh)\n",
    "            \n",
    "            y_pred_ = torch.clone(y_pred)\n",
    "            y_pred_[y_pred_ > 0.5] = 1\n",
    "            y_pred_[y_pred_ <= 0.5] = 0\n",
    "            EpochNorm.append(np.sum(y_pred_.detach().numpy() == y) / len(y))\n",
    "            EpochNaive.append(np.sum(y==0) / len(y))\n",
    "            \n",
    "        if np.mean(EpochLoss) < minloss:\n",
    "            #print(f\"\\nloss improved from {minloss :.3f} to {np.mean(EpochLoss):.3f} Saving...\")\n",
    "            torch.save(Models[i].state_dict(), \n",
    "                   f=f\"{PATH_SAVE_TRAINS}{layers[i]}_seed_{seed}_thr_{int(threshold*10)}_date_{dt_string}.pt\")\n",
    "            minloss = np.mean(EpochLoss)\n",
    "            bestacc = np.mean(EpochAcc)\n",
    "            bestaccnorm = np.mean(EpochNorm)\n",
    "            \n",
    "            \n",
    "\n",
    "        if epoch%20 == 0:\n",
    "            \n",
    "            print(f\"Epoch {epoch} - Loss: {np.mean(EpochLoss):.2f} - Mean Acc {np.mean(EpochAcc):.2f} - MDH {np.mean(EpochMDH):.2f} - Acc Norm {np.mean(EpochNorm):.3f} - AccNaive {np.mean(EpochNaive):.3f}\")\n",
    "    print(f\"\\nFinal Epoch - Best Loss: {minloss:.2f} - Best Acc {bestacc:.2f} - MDH {np.mean(EpochMDH):.2f} - Best Acc Norm {bestaccnorm:.3f} - AccNaive {np.mean(EpochNaive):.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c6170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de43db92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb414f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230c1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1f6348c",
   "metadata": {},
   "source": [
    "## Adding new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9e0972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T15:16:46.554093Z",
     "start_time": "2022-12-17T15:07:27.836559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ 1 out of 2 ------------\n",
      "\n",
      "\n",
      "Next graph: Amazon0302.txt\n",
      "\n",
      "Time elapsed: 137.735\n",
      "\n",
      "------------ 2 out of 2 ------------\n",
      "\n",
      "\n",
      "Next graph: Amazon0312.txt\n",
      "\n",
      "Time elapsed: 375.686\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[152]:\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "\n",
    "#PATH = \"./BRKGA/instances/Erdos/test/txt/\"\n",
    "#PATH_save = \"./BRKGA/instances/Erdos/test/feats/\"\n",
    "\n",
    "PATH = \"./BRKGA/instances/socialnetworks/txt/\"\n",
    "PATH_save = \"./BRKGA/instances/socialnetworks/feats/\"\n",
    "\n",
    "\n",
    "#PATH = './BRKGA/instances/Erdos/test/txt/'\n",
    "#PATH_save = './BRKGA/instances/Erdos/test/feats/'\n",
    "#python savefeats.py -p \"./BRKGA/instances/Erdos/test/txt/\" -ps \"./BRKGA/instances/Erdos/test/feats/\"\n",
    "#python savefeats.py -p \"./BRKGA/instances/Erdos/test/txt/\" -ps \"./BRKGA/instances/Erdos/test/feats/\"\n",
    "\n",
    "\n",
    "def getFeatures(G):\n",
    "    \n",
    "    #BC = np.array(list(nx.betweenness_centrality(G, k = 500).values()))\n",
    "    #CC = np.array(list(nx.closeness_centrality(G).values()))\n",
    "    #LC = np.array(list(nx.load_centrality(G).values()))\n",
    "    #DG = np.array(list(nx.degree(G))).T[1]\n",
    "    #PR = np.array(list(nx.pagerank(G).values()))\n",
    "    \n",
    "    EC = np.array(list(nx.eigenvector_centrality(G, max_iter = 200).values()))\n",
    "\n",
    "    #features = [BC, PR, DG, CC]#, LC]\n",
    "    features = [EC]#, LC]\n",
    "    names = [\"EC\"]#, \"LC\"]\n",
    "    return np.array(features).T, names\n",
    "\n",
    "\n",
    "# In[227]:\n",
    "\n",
    "\n",
    "def writeFeatures(PATH, ins, features, elapsed):\n",
    "    subfij = '_feat'\n",
    "    with open(PATH + ins.split(\"/\")[-1].replace(\".txt\",\"\") + subfij + \"_EC.npy\", \"wb\") as f:\n",
    "        np.save(f, features, allow_pickle=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    file2 = open(, 'w')\n",
    "    c = 0\n",
    "    \n",
    "    file2.write(f\"time: {elapsed}, n: {features.shape[0]}\")\n",
    "    file2.write('\\n')\n",
    "    \n",
    "    for f in features:\n",
    "        st = \",\".join(str(x) for x in f)\n",
    "        file2.write(st)\n",
    "        file2.write('\\n')\n",
    "        c += 1\n",
    "    file2.close()\n",
    "    print(f\"para {ins} se escribieron {c} lines\")\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# In[231]:\n",
    "\n",
    "graphs = [graph for graph in os.listdir(PATH)]\n",
    "graphs.sort(reverse = False)\n",
    "graphs = graphs[:2]\n",
    "Graphs = []\n",
    "\n",
    "for ins in graphs:\n",
    "    file1 = open(PATH+ins, 'r')\n",
    "    \n",
    "    Lines = file1.readlines()\n",
    "    VectorList = []\n",
    "    for line in Lines:\n",
    "        VectorList.append(line.replace(\"\\n\",\"\"))\n",
    "\n",
    "    file1.close()\n",
    "    G2 = nx.parse_edgelist(VectorList, nodetype=int)\n",
    "\n",
    "    H = nx.Graph()\n",
    "    H.add_nodes_from(sorted(G2.nodes(data=True)))\n",
    "    H.add_edges_from(G2.edges(data=True))\n",
    "    \"\"\"\n",
    "    G = igraph.Graph.Read_Edgelist(PATH+ins, directed = False)\n",
    "    G = G.to_networkx()\n",
    "    \"\"\"\n",
    "    Graphs.append(H)\n",
    "\n",
    "# In[229]:\n",
    "\n",
    "c = 0\n",
    "for G, ins in zip(Graphs, graphs):\n",
    "    c+=1\n",
    "    print(f\"\\n------------ {c} out of {len(Graphs)} ------------\\n\")\n",
    "    print(f\"\\nNext graph: {ins}\")\n",
    "    \n",
    "    s = time.time()\n",
    "    features, _ = getFeatures(G)\n",
    "    elapsed = time.time() - s\n",
    "    print(f\"\\nTime elapsed: {elapsed:.3f}\")\n",
    "    \n",
    "    writeFeatures(PATH_save, ins, features, elapsed)\n",
    "    \n",
    "\n",
    "\n",
    "# In[204]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87dab256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T13:39:42.979580Z",
     "start_time": "2022-12-17T13:39:42.953985Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(PATH_save + \"ER_50000_20_0_feat_EC.npy\", \"rb\") as f:\n",
    "        f = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b593e831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T15:04:30.915025Z",
     "start_time": "2022-12-17T14:54:18.367942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ 1 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: socfb-nips-ego.txt\n",
      "\n",
      "Time elapsed: 0.699\n",
      "\n",
      "------------ 2 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: socfb-Mich67.txt\n",
      "\n",
      "Time elapsed: 1.115\n",
      "\n",
      "------------ 3 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: socfb-Brandeis99.txt\n",
      "\n",
      "Time elapsed: 1.630\n",
      "\n",
      "------------ 4 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: soc-gplus.txt\n",
      "\n",
      "Time elapsed: 3.713\n",
      "\n",
      "------------ 5 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: musae_git.txt\n",
      "\n",
      "Time elapsed: 5.992\n",
      "\n",
      "------------ 6 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: loc-gowalla_edges.txt\n",
      "\n",
      "Time elapsed: 22.054\n",
      "\n",
      "------------ 7 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: graph_ncstrlwg2.txt\n",
      "\n",
      "Time elapsed: 2.349\n",
      "\n",
      "------------ 8 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: graph_karate.txt\n",
      "\n",
      "Time elapsed: 0.015\n",
      "\n",
      "------------ 9 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: graph_jazz.txt\n",
      "\n",
      "Time elapsed: 0.031\n",
      "\n",
      "------------ 10 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: graph_football.txt\n",
      "\n",
      "Time elapsed: 0.016\n",
      "\n",
      "------------ 11 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: graph_dolphins.txt\n",
      "\n",
      "Time elapsed: 0.008\n",
      "\n",
      "------------ 12 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: graph_actors_dat.txt\n",
      "\n",
      "Time elapsed: 1.587\n",
      "\n",
      "------------ 13 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: graph_Email-Enron.txt\n",
      "\n",
      "Time elapsed: 1.814\n",
      "\n",
      "------------ 14 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: graph_CA-HepTh.txt\n",
      "\n",
      "Time elapsed: 0.565\n",
      "\n",
      "------------ 15 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: graph_CA-HepPh.txt\n",
      "\n",
      "Time elapsed: 0.683\n",
      "\n",
      "------------ 16 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: graph_CA-GrQc.txt\n",
      "\n",
      "Time elapsed: 0.466\n",
      "\n",
      "------------ 17 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: graph_CA-CondMat.txt\n",
      "\n",
      "Time elapsed: 2.339\n",
      "\n",
      "------------ 18 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: graph_CA-AstroPh.txt\n",
      "\n",
      "Time elapsed: 2.755\n",
      "\n",
      "------------ 19 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: gemsec_facebook_artist.txt\n",
      "\n",
      "Time elapsed: 22.030\n",
      "\n",
      "------------ 20 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: ego-facebook.txt\n",
      "\n",
      "Time elapsed: 1.230\n",
      "\n",
      "------------ 21 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: deezer_HR.txt\n",
      "\n",
      "Time elapsed: 15.830\n",
      "\n",
      "------------ 22 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: com-youtube.ungraph.txt\n",
      "\n",
      "Time elapsed: 128.499\n",
      "\n",
      "------------ 23 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: com-dblp.ungraph.txt\n",
      "\n",
      "Time elapsed: 25.843\n",
      "\n",
      "------------ 24 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: Amazon0601.txt\n",
      "\n",
      "Time elapsed: 190.435\n",
      "\n",
      "------------ 25 out of 25 ------------\n",
      "\n",
      "\n",
      "Next graph: Amazon0505.txt\n",
      "\n",
      "Time elapsed: 166.730\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for G, ins in zip(Graphs, graphs):\n",
    "    c+=1\n",
    "    print(f\"\\n------------ {c} out of {len(Graphs)} ------------\\n\")\n",
    "    print(f\"\\nNext graph: {ins}\")\n",
    "    \n",
    "    s = time.time()\n",
    "    features, _ = getFeatures(G)\n",
    "    elapsed = time.time() - s\n",
    "    print(f\"\\nTime elapsed: {elapsed:.3f}\")\n",
    "    \n",
    "    writeFeatures(PATH_save, ins, features, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad850ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T14:54:06.881436Z",
     "start_time": "2022-12-17T14:54:06.873392Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFeatures(G):\n",
    "    \n",
    "    #BC = np.array(list(nx.betweenness_centrality(G, k = 500).values()))\n",
    "    #CC = np.array(list(nx.closeness_centrality(G).values()))\n",
    "    #LC = np.array(list(nx.load_centrality(G).values()))\n",
    "    #DG = np.array(list(nx.degree(G))).T[1]\n",
    "    #PR = np.array(list(nx.pagerank(G).values()))\n",
    "    \n",
    "    EC = np.array(list(nx.eigenvector_centrality(G, max_iter = 200).values()))\n",
    "\n",
    "    #features = [BC, PR, DG, CC]#, LC]\n",
    "    features = [EC]#, LC]\n",
    "    names = [\"EC\"]#, \"LC\"]\n",
    "    return np.array(features).T, names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4f5b4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T15:07:12.626263Z",
     "start_time": "2022-12-17T15:07:12.609117Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = \"./BRKGA/instances/socialnetworks/txt/\"\n",
    "graphs = [graph for graph in os.listdir(PATH)]\n",
    "graphs.sort(reverse = False)\n",
    "graphs = graphs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b31c31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-17T15:07:14.015188Z",
     "start_time": "2022-12-17T15:07:13.995990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amazon0302.txt', 'Amazon0312.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
