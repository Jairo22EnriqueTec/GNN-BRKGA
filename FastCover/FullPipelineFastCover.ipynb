{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-19T08:07:35.008797Z",
     "start_time": "2022-10-19T08:07:32.127220Z"
    }
   },
   "outputs": [],
   "source": [
    "import igraph\n",
    "import dgl\n",
    "import torch\n",
    "import heapq\n",
    "import time\n",
    "import pickle\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones heurísticas para comparar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:36:31.369176Z",
     "start_time": "2022-10-08T18:36:31.356617Z"
    }
   },
   "outputs": [],
   "source": [
    "def bfs(graph: igraph.Graph, d: int):\n",
    "    if d <= 1:\n",
    "        return graph.copy()\n",
    "\n",
    "    n = graph.vcount()\n",
    "    es = []\n",
    "\n",
    "    for v in range(n):\n",
    "        layers = [0] * n\n",
    "        visited, queue = set([v]), deque([v])\n",
    "        while queue:\n",
    "            vertex = queue.popleft()\n",
    "            for neighbor in graph.successors(vertex):\n",
    "                if neighbor not in visited and layers[vertex] < d:\n",
    "                    visited.add(neighbor) \n",
    "                    queue.append(neighbor)\n",
    "                    layers[neighbor] = layers[vertex] + 1\n",
    "        visited.remove(v)\n",
    "        es.extend([(v, u) for u in visited])\n",
    "    \n",
    "    extended_graph = igraph.Graph(n=n, directed=True)\n",
    "    extended_graph.add_edges(es)\n",
    "    return extended_graph\n",
    "class Node:\n",
    "    def __init__(self, id, value):\n",
    "        self.id = id\n",
    "        self.value = value\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.value < other.value\n",
    "\n",
    "    def __str__(self):\n",
    "        # we store the negative value to use max heap.\n",
    "        return f\"{self.id}: {-self.value}\"\n",
    "    \n",
    "def greedy(closed_graph: igraph.Graph, k: int, debug=False):\n",
    "    \"\"\"find k-max d-hop cover with greedy\n",
    "\n",
    "    Args:\n",
    "        graph (igraph.Graph): graph\n",
    "        k (int): the number of seeds k\n",
    "        debug (bool): debug mode\n",
    "\n",
    "    Returns:\n",
    "        seeds, covernum: selected seeds, and the seed count\n",
    "    \"\"\"\n",
    "    seeds = []\n",
    "\n",
    "    nodes_num = closed_graph.vcount()\n",
    "    covered = [False] * nodes_num\n",
    "    cover_num = 0\n",
    "\n",
    "    inf_list = [deg + 1 for deg in closed_graph.outdegree()]\n",
    "\n",
    "    node_queue = [Node(i, -inf_list[i]) for i in range(nodes_num)]\n",
    "    heapq.heapify(node_queue)\n",
    "    i = 0\n",
    "\n",
    "    while i < k and cover_num < nodes_num:  # while there's still free point or unused budget\n",
    "\n",
    "        # Find the node with max marginal utility\n",
    "        max_inf_node = heapq.heappop(node_queue)\n",
    "        if inf_list[max_inf_node.id] != - max_inf_node.value:\n",
    "            max_inf_node.value = -inf_list[max_inf_node.id]\n",
    "            heapq.heappush(node_queue, max_inf_node)\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "        seeds.append(max_inf_node.id)\n",
    "        if not covered[max_inf_node.id]:  # Update predecessors\n",
    "            covered[max_inf_node.id] = True  # 1. mark max_node as covered\n",
    "            cover_num += 1\n",
    "            inf_list[max_inf_node.id] -= 1\n",
    "            # 2. all the preds have influence -1\n",
    "            for predecessor in closed_graph.predecessors(max_inf_node.id):\n",
    "                inf_list[predecessor] -= 1\n",
    "\n",
    "        # Update successors\n",
    "        for successor in closed_graph.successors(max_inf_node.id):\n",
    "            if not covered[successor]:\n",
    "                # 1. mark all the successors as covered\n",
    "                covered[successor] = True\n",
    "                cover_num += 1\n",
    "                # 2. all the successors have influence -1 (since there is no unitility to cover themselves)\n",
    "                inf_list[successor] -= 1\n",
    "                # 3. all the (predecessors of successors) have influence -1\n",
    "                for predecessor in closed_graph.predecessors(successor):\n",
    "                    inf_list[predecessor] -= 1\n",
    "\n",
    "        if debug:\n",
    "            print(\n",
    "                f\"Round {i}: {max_inf_node.id} is selected. {cover_num} nodes are covered.\")\n",
    "                \n",
    "    return seeds, cover_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:36:32.368985Z",
     "start_time": "2022-10-08T18:36:32.349764Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_adj_mat(graph, d=1):\n",
    "    if d == 1:\n",
    "        adj_mat = np.array(graph.get_adjacency().data, dtype=bool)\n",
    "        adj_mat = torch.from_numpy(np.array(adj_mat, dtype=int)).float().cpu()\n",
    "        adj_mat += torch.eye(graph.vcount()).cpu()\n",
    "        return adj_mat.cpu()\n",
    "    elif d == 2:\n",
    "        return get_adj_mat_2(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones necesarias para correr el código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:36:32.793024Z",
     "start_time": "2022-10-08T18:36:32.786193Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_graph_names(path_to_test):\n",
    "    graph_names = []\n",
    "    for rt, _, files in os.walk(path_to_test):\n",
    "        if rt == path_to_test:\n",
    "            for file in files:\n",
    "                if file.endswith('.txt'):\n",
    "                    graph_names.append(file)\n",
    "    return graph_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-19T08:14:36.443270Z",
     "start_time": "2022-10-19T08:14:36.417655Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_zero_feature(graph, feature_dim):\n",
    "    \"\"\"Generate all-zero features\n",
    "    \"\"\"\n",
    "    return torch.zeros(graph.vcount(), feature_dim)\n",
    "\n",
    "\n",
    "def gen_one_feature(graph, feature_dim):\n",
    "    \"\"\"Generate all-one features\n",
    "    \"\"\"\n",
    "    return torch.ones(graph.vcount(), feature_dim)\n",
    "\n",
    "\n",
    "def gen_deg_feature(graph, *args):  # args is only a placeholder\n",
    "    indegree = torch.tensor(graph.indegree()).float()\n",
    "    zeros = torch.zeros(graph.vcount(), 1).squeeze(1)\n",
    "    return torch.stack([indegree, zeros], dim=1)\n",
    "\n",
    "\n",
    "def gen_one_hot_feayture(graph, *args):  # args is only a placeholder\n",
    "    return torch.eye(graph.vcount()).float()\n",
    "\n",
    "\n",
    "FEATURE_TYPE_DICT = {\n",
    "    \"0\": gen_zero_feature,\n",
    "    \"1\": gen_one_feature,\n",
    "    \"onehot\": gen_one_hot_feayture,\n",
    "    \"deg\": gen_deg_feature,\n",
    "}\n",
    "\n",
    "def get_rev_dgl(graph, feature_type='0', feature_dim=None, is_directed=False, use_cuda=False):\n",
    "    \"\"\"get dgl graph from igraph\n",
    "    \"\"\"\n",
    "    \n",
    "    src, dst = zip(*graph.get_edgelist())\n",
    "\n",
    "    if use_cuda:\n",
    "        dglgraph = dgl.graph((dst, src)).to(torch.device(\"cuda:0\"))\n",
    "    else:\n",
    "        dglgraph = dgl.graph((dst, src))\n",
    "        \n",
    "    if not is_directed:\n",
    "        dglgraph.add_edges(src, dst)\n",
    "\n",
    "    if use_cuda:\n",
    "        dglgraph.ndata['feat'] = FEATURE_TYPE_DICT[feature_type](graph, feature_dim).cuda()\n",
    "        dglgraph.ndata['degree'] = torch.tensor(graph.degree()).float().cuda()\n",
    "\n",
    "    else:\n",
    "        dglgraph.ndata['feat'] = FEATURE_TYPE_DICT[feature_type](graph, feature_dim)\n",
    "        dglgraph.ndata['degree'] = torch.tensor(graph.degree()).float()\n",
    "        \n",
    "    return dglgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:36:33.138155Z",
     "start_time": "2022-10-08T18:36:33.119873Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch.softmax import edge_softmax\n",
    "# Guanhao's GRAT\n",
    "class GRATLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        # TODO: why not another linear layer before entering the net\n",
    "        super(GRATLayer, self).__init__()\n",
    "        # linear layer\n",
    "        self.fc = nn.Linear(in_feats, out_feats, bias=True)  # bias=True in Guanhao's original code\n",
    "        \n",
    "        # attention layer\n",
    "        self.attn_fc = nn.Linear(2 * in_feats, 1, bias=True)  # bias=True in Guanhao's original code\n",
    "\n",
    "        # initialize parameters\n",
    "        # self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        h2 = torch.cat([edges.src['h'], edges.dst['h']], dim=1)\n",
    "        a = self.attn_fc(h2)\n",
    "        return {'e': torch.relu(a)}\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        return {'h': edges.src['h'] * edges.data['alpha']}  # message divided by weight\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        return {'h': torch.sum(nodes.mailbox['h'], dim=1)}\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = feature\n",
    "            # Equation (2)\n",
    "            g.apply_edges(self.edge_attention)  # calculate e_{ij}\n",
    "\n",
    "            # Calculate softmax on source code -> on the reversed graph\n",
    "            rg = g.reverse(copy_ndata=False, copy_edata=True)\n",
    "            g.edata['alpha'] = edge_softmax(rg, rg.edata['e'])\n",
    "            \n",
    "            # Convolution\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            \n",
    "            g.ndata['h'] = self.fc(g.ndata['h'])\n",
    "            h = g.ndata['h']\n",
    "            return h\n",
    "\n",
    "\n",
    "# GRAT more similar to GAT \n",
    "class GRATVLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GRATVLayer, self).__init__()\n",
    "        # linear layer\n",
    "        self.fc = nn.Linear(in_feats, out_feats, bias=False)  # bias=True in Guanhao's original code\n",
    "        # attention layer\n",
    "        self.attn_fc = nn.Linear(2 * out_feats, 1, bias=False)  # bias=True in Guanhao's original code\n",
    "        # initialize parameters\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "        return {'e': F.leaky_relu(a)}\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        return {'h': edges.src['z'] * edges.data['alpha']}  # message divided by weight\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        return {'h': torch.sum(nodes.mailbox['h'], dim=1)}\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        with g.local_scope():\n",
    "            z = self.fc(feature)\n",
    "            g.ndata['z'] = z\n",
    "            # Equation (2)\n",
    "            g.apply_edges(self.edge_attention)  # calculate e_{ij}\n",
    "            # Calculate softmax on source code -> on the reversed graph\n",
    "            rg = g.reverse(copy_ndata=False, copy_edata=True)\n",
    "            g.edata['alpha'] = edge_softmax(rg, rg.edata['e'])\n",
    "            # Equation (3)\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            # output            \n",
    "            h = g.ndata['h']\n",
    "            return h\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:36:33.296521Z",
     "start_time": "2022-10-08T18:36:33.276869Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class GRAT3_(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats1, hidden_feats2, out_feats, *args):\n",
    "        super(GRAT3_, self).__init__()\n",
    "        self.grat1 = GRATLayer(in_feats, hidden_feats1)\n",
    "        self.grat2 = GRATLayer(hidden_feats1, hidden_feats2)\n",
    "        self.grat3 = GRATLayer(hidden_feats2, out_feats)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        h = torch.relu(self.grat1(g, feature))\n",
    "        h = torch.relu(self.grat2(g, h))\n",
    "        h = self.grat3(g, h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class GRAT3(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats1, hidden_feats2, *args):\n",
    "        super(GRAT3, self).__init__()\n",
    "        self.grat = GRAT3_(in_feats, hidden_feats1, hidden_feats2, 1, *args)  # out_feats=1\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        h = self.grat(g, feature)\n",
    "        h = torch.sigmoid(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:36:33.450969Z",
     "start_time": "2022-10-08T18:36:33.429242Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_influence(graph, seeds):\n",
    "    if torch.is_tensor(seeds):\n",
    "        seeds = seeds.int().tolist()\n",
    "\n",
    "    covered = set()\n",
    "    for seed in seeds:\n",
    "        covered.add(int(seed))\n",
    "        for u in graph.successors(seed):  # Add all the covered seeds\n",
    "            covered.add(u)\n",
    "    return len(covered)\n",
    "\n",
    "class KSetMaxCoverLoss(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "\n",
    "    def forward(self, v, graph, *args):\n",
    "        adj_mat = np.array(graph.get_adjacency().data, dtype=np.int32)\n",
    "        adj_mat = torch.from_numpy(np.array(adj_mat, dtype=int)).float()\n",
    "        adj_mat += torch.eye(graph.vcount())\n",
    "        adj_mat = adj_mat.cpu()\n",
    "        tmp = 1 - v.unsqueeze(1) * adj_mat\n",
    "        tmp = torch.prod(tmp, dim=0)\n",
    "        loss1 = torch.sum(tmp)\n",
    "        loss2 = torch.sum(v)\n",
    "        return loss1 + self.C * loss2\n",
    "\n",
    "\n",
    "class KSetMaxCoverAdjLoss(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "\n",
    "    def forward(self, v, adj_mat, *args):\n",
    "        tmp = 1 - v.unsqueeze(1) * adj_mat.cpu()\n",
    "        tmp = torch.prod(tmp, dim=0)\n",
    "        loss1 = torch.sum(tmp)\n",
    "        loss2 = torch.sum(v)\n",
    "        return loss1 + self.C * loss2\n",
    "\n",
    "\n",
    "class KSetMaxCoverLossSigmoid(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "\n",
    "    def forward(self, v, graph, k):\n",
    "        print(0, flush=True)\n",
    "        adj_mat = np.array(graph.get_adjacency().data, dtype=np.int32)\n",
    "        #adj_mat = torch.from_numpy(np.array(adj_mat, dtype=int)).float().cpu()  # TODO: make it adaptive to non-cuda env\n",
    "        adj_mat = torch.from_numpy(np.array(adj_mat, dtype=int)).float().cuda()  # TODO: make it adaptive to non-cuda env\n",
    "        adj_mat += torch.eye(graph.vcount())\n",
    "        v = torch.sigmoid(v)\n",
    "        print(1, flush=True)\n",
    "        tmp = 1 - v.unsqueeze(1)*adj_mat\n",
    "        print(2, flush=True)\n",
    "        tmp = torch.prod(tmp, dim=0)\n",
    "        loss1 = torch.sum(tmp)\n",
    "        loss2 = torch.relu(torch.sum(v)-k)  # Loss with threshold (hinge loss-like)\n",
    "        return loss1 + self.C * loss2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:36:34.402150Z",
     "start_time": "2022-10-08T18:36:34.385786Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:36:34.667906Z",
     "start_time": "2022-10-08T18:36:34.646859Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_single(net, optimizer, n_epoch, loss_function, adj_mat, graph, dglgraph, greedy_perf, k, closed_graph=None):\n",
    "    \"\"\"helper function of train\n",
    "    \"\"\"\n",
    "    loss_list = []\n",
    "    for _ in range(n_epoch):\n",
    "        out = net(dglgraph, dglgraph.ndata['feat']).squeeze(1)\n",
    "        loss = loss_function(out, adj_mat, k)\n",
    "        loss_list.append(float(loss.data))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    logits = net.grat(dglgraph, dglgraph.ndata['feat']).squeeze(\n",
    "        1)\n",
    "        \n",
    "    _, indices = torch.topk(logits, k)\n",
    "\n",
    "    if closed_graph is None:\n",
    "        train_perf = get_influence(graph, indices)\n",
    "    else:\n",
    "        train_perf = get_influence(closed_graph, indices)\n",
    "    \n",
    "    perf_ratio = train_perf/greedy_perf\n",
    "    print(f\"Train influence: {train_perf}/{greedy_perf}={perf_ratio:.2f}\")\n",
    "    return loss_list, perf_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para convertir de dimacs a txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-19T08:14:26.929628Z",
     "start_time": "2022-10-19T08:14:26.922621Z"
    }
   },
   "outputs": [],
   "source": [
    "def Dimacs2Txt(ruta):\n",
    "    file1 = open(ruta, 'r')\n",
    "    Lines = file1.readlines()\n",
    "    newname = ruta.split(\".\")[0]+\".txt\"\n",
    "    file2 = open(newname, 'w')\n",
    "    #file1.writelines(L)\n",
    "    file1.close()\n",
    "    for line in Lines[1:]:\n",
    "        v = line.strip().split()\n",
    "        file2.write(f\"{int(v[1])-1} {int(v[2])-1}\")\n",
    "        file2.write('\\n')\n",
    "    file2.close()\n",
    "    return newname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:31:16.942389Z",
     "start_time": "2022-10-08T18:31:16.915241Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATH_TO_TRAIN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a80ed66f60c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0migraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRead_Edgelist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDimacs2Txt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{PATH_TO_TRAIN}musae_git.dimacs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdglgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_rev_dgl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFEATURE_TYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirected_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PATH_TO_TRAIN' is not defined"
     ]
    }
   ],
   "source": [
    "graph = igraph.Graph().Read_Edgelist(Dimacs2Txt(f\"{PATH_TO_TRAIN}musae_git.dimacs\"), directed=False)\n",
    "\n",
    "dglgraph = get_rev_dgl(graph, FEATURE_TYPE, input_dim, directed_train, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando una lista de grafos no dirigidos y guardando sus valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-19T08:15:55.513354Z",
     "start_time": "2022-10-19T08:15:47.551790Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_LIST_ = [\n",
    "     \"fb-pages-tvshow.txt\",\n",
    "     \"fb-pages-politician.txt\",\n",
    "     \"fb-pages-government.txt\",\n",
    "     \"fb-pages-public-figure.txt\"\n",
    "]\n",
    "TRAIN_LIST_ = [\n",
    "#\"graph_CA-GrQc.dimacs\",\n",
    "\"socfb-Mich67.dimacs\",\n",
    "    \"Amazon0302.dimacs\"\n",
    "]\n",
    "\n",
    "TEST_LIST_ = [\n",
    "\"musae_git.dimacs\"\n",
    "]\n",
    "\n",
    "PATH_TO_TRAIN = \"data/undirected/\"\n",
    "PATH_TO_TRAIN = \"../BRKGA/instances/dimacs/\"\n",
    "\n",
    "#TRAIN_LIST = get_graph_names(PATH_TO_TRAIN)\n",
    "\n",
    "FEATURE_TYPE = \"1\"\n",
    "input_dim = 32\n",
    "directed_train = False\n",
    "use_cuda = False\n",
    "\n",
    "graphs = []\n",
    "graph_names = []\n",
    "dglgraphs = []\n",
    "\n",
    "is_directed = False\n",
    "\n",
    "\n",
    "for file in TRAIN_LIST_:\n",
    "    #\"\"\"\n",
    "    graph = igraph.Graph().Read_Edgelist(\n",
    "        Dimacs2Txt(f\"{PATH_TO_TRAIN}{file}\"), directed=False)\n",
    "\n",
    "    graphs.append(graph)\n",
    "    \"\"\"\n",
    "    graph = igraph.Graph().Read_Edgelist(\n",
    "        f\"{PATH_TO_TRAIN}{file}\", directed=False)\n",
    "\n",
    "    graphs.append(graph)\n",
    "    \"\"\"\n",
    "    dglgraph = get_rev_dgl(graph, FEATURE_TYPE, input_dim, directed_train, use_cuda)\n",
    "    \n",
    "    dglgraphs.append(dglgraph)\n",
    "\n",
    "    graph_name = file\n",
    "    graph_names.append(graph_name)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-19T08:16:26.954302Z",
     "start_time": "2022-10-19T08:16:26.946156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=3748, num_edges=163806,\n",
       "      ndata_schemes={'feat': Scheme(shape=(32,), dtype=torch.float32), 'degree': Scheme(shape=(), dtype=torch.float32)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dglgraphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:39:15.067063Z",
     "start_time": "2022-10-08T18:39:15.053724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20c6e4daed0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 1\n",
    "k = 20\n",
    "seed = 616\n",
    "\n",
    "HIDDEN_FEATS = [32, 32, 32, 32, 32, 32]\n",
    "\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:38:15.636443Z",
     "start_time": "2022-10-08T18:38:11.840261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy influence: 1958/5242\n",
      "Greedy influence: 2888/2888\n"
     ]
    }
   ],
   "source": [
    "adj_matrices = []\n",
    "greedy_perfs = []\n",
    "closed_graphs = []\n",
    "\n",
    "for graph in graphs:\n",
    "    \n",
    "    closed_graph = bfs(graph, d)\n",
    "    closed_graphs.append(closed_graph)\n",
    "    \n",
    "    adj_matrix = get_adj_mat(closed_graph)\n",
    "    adj_matrices.append(adj_matrix)\n",
    "    \n",
    "    _, n_covered = greedy(closed_graph, k=k)\n",
    "    \n",
    "    greedy_perfs.append(n_covered)\n",
    "    \n",
    "    print(f\"Greedy influence: {n_covered}/{closed_graph.vcount()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:38:18.222020Z",
     "start_time": "2022-10-08T18:38:18.205400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRAT3(\n",
       "  (grat): GRAT3_(\n",
       "    (grat1): GRATLayer(\n",
       "      (fc): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (attn_fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "    (grat2): GRATLayer(\n",
       "      (fc): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (attn_fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "    (grat3): GRATLayer(\n",
       "      (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (attn_fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = GRAT3(*HIDDEN_FEATS)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:40:12.044725Z",
     "start_time": "2022-10-08T18:39:23.366758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train influence: 580/1958=0.30\n",
      "Train influence: 2888/2888=1.00\n",
      "Train Epoch 0 | Loss: 937.18 | Perf: 0.65 | Elapsed Time: 24.54\n",
      "\n",
      "Validation loss decreased (inf --> -0.648110).  Saving model ...\n",
      "Train influence: 580/1958=0.30\n",
      "Train influence: 2888/2888=1.00\n",
      "Train Epoch 1 | Loss: 936.51 | Perf: 0.65 | Elapsed Time: 24.11\n",
      "\n",
      "Validation loss decreased (-0.648110 --> -0.648110).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "#def train(net, adj_matrices, graphs, dglgraphs, loss_function, greedy_perfs, \n",
    "# closed_graphs=None, k_train=1, n_epoch=5, n_batch=10, lr=0.1, save_filename=None, patience=5):\n",
    "lr = 0.01\n",
    "n_epoch = 2\n",
    "n_batch = 10\n",
    "patience = 5\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    \n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# EarlyStopping Module\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "avg_train_losses = []\n",
    "avg_valid_losses = [] \n",
    "\n",
    "# cover performence\n",
    "train_perfs = []\n",
    "avg_train_perfs = []\n",
    "# initialize the early_stopping object\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "if closed_graph is None:\n",
    "    closed_graph = [None] * len(graphs)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    timer = time.time()\n",
    "    for adj_mat, graph, dglgraph, greedy_perf, closed_graph in zip(adj_matrices, graphs, dglgraphs, greedy_perfs, closed_graphs):\n",
    "        # train the i_th graph\n",
    "        loss_list, perf = train_single(\n",
    "            net, optimizer, n_batch, KSetMaxCoverAdjLoss(1), adj_mat, graph, dglgraph, greedy_perf, k, closed_graph\n",
    "        )\n",
    "        train_perfs.append(perf)\n",
    "        train_losses.append(sum(loss_list)/n_batch)  # track losses\n",
    "\n",
    "    train_loss = np.average(train_losses)\n",
    "    avg_train_losses.append(train_loss)\n",
    "\n",
    "    train_perf = np.average(train_perfs)\n",
    "    avg_train_perfs.append(train_perf)\n",
    "\n",
    "    #logging.info(f\"Train Epoch {epoch} | Loss: {train_loss:.2f} | Perf: {train_perf:.2f} | Elapsed Time: {time.time() - timer:.2f}\")\n",
    "    print(f\"Train Epoch {epoch} | Loss: {train_loss:.2f} | Perf: {train_perf:.2f} | Elapsed Time: {time.time() - timer:.2f}\")\n",
    "    print()\n",
    "    # if save_filename:\n",
    "    #     torch.save(net.state_dict(), f=f\"{save_filename}-epoch-{epoch}.pt\")\n",
    "    #     logging.debug(f\"Epoch {epoch} saved.\")\n",
    "\n",
    "    # clear lists to track next epoch\n",
    "    train_losses = []\n",
    "    train_perfs = []\n",
    "    # valid_losses = []\n",
    "\n",
    "    # early_stopping(train_loss, net)\n",
    "    early_stopping(-train_perf, net)\n",
    "    if early_stopping.early_stop:\n",
    "        logging.info(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# load the last checkpoint with the best model\n",
    "net.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "net.cpu()\n",
    "torch.save(net.state_dict(), f=f\"{'Ejemplo'}_semilla_{seed}.pt\")  # Change the path\n",
    "with open(f\"{'Ejemplo'}_semilla_{seed}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(loss_list, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:40:17.794805Z",
     "start_time": "2022-10-08T18:40:17.684591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8598e+04, -7.7907e+00, -7.7907e+00,  ..., -7.7907e+00,\n",
       "        -7.7907e+00, -7.7907e+00], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.grat(dglgraph, dglgraph.ndata['feat']).squeeze(1)#!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:40:18.449717Z",
     "start_time": "2022-10-08T18:40:18.438216Z"
    }
   },
   "outputs": [],
   "source": [
    "net = GRAT3(*HIDDEN_FEATS)\n",
    "net.load_state_dict(torch.load(f\"{'Ejemplo'}_semilla_{seed}.pt\"))\n",
    "if use_cuda:\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:40:20.906061Z",
     "start_time": "2022-10-08T18:40:20.804685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8597572e+04, -7.7907400e+00, -7.7907400e+00, ...,\n",
       "       -7.7907400e+00, -7.7907400e+00, -7.7907400e+00], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.grat(dglgraph, dglgraph.ndata['feat']).squeeze(1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:40:23.018102Z",
     "start_time": "2022-10-08T18:40:23.008911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Graph(num_nodes=5242, num_edges=28968,\n",
       "       ndata_schemes={'feat': Scheme(shape=(32,), dtype=torch.float32), 'degree': Scheme(shape=(), dtype=torch.float32)}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=2888, num_edges=5962,\n",
       "       ndata_schemes={'feat': Scheme(shape=(32,), dtype=torch.float32), 'degree': Scheme(shape=(), dtype=torch.float32)}\n",
       "       edata_schemes={})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dglgraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aun resta incluir que se evaluen en otros diferentes, hacer un test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-08T18:40:29.260320Z",
     "start_time": "2022-10-08T18:40:29.038790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 20. Coverage: 2888/2888=1.00. Time: 0.07 (0.01)\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "repeat = 3\n",
    "ts = np.zeros(repeat)\n",
    "for i in range(repeat):\n",
    "    # Select seeds\n",
    "    t_start = time.time()\n",
    "    ## =================================================================================================\n",
    "    # Este es el output de la red, en donde se tienen las probabilidades de que cada nodo sea parte de la\n",
    "    # solución final\n",
    "    ## =================================================================================================\n",
    "    out = net.grat(dglgraph, dglgraph.ndata['feat']).squeeze(1)#!!!!!!!!!!!!!!\n",
    "    ## =================================================================================================\n",
    "    # Esta función regresas el k nodos con la máxima influencia\n",
    "    _, nn_seeds = torch.topk(out, k)\n",
    "    ## =================================================================================================\n",
    "    ts[i] = (time.time() - t_start)\n",
    "\n",
    "# Evaluate time\n",
    "t_mean = ts.mean() \n",
    "t_std = ts.std() / np.sqrt(repeat)\n",
    "\n",
    "## =================================================================================================\n",
    "# Nodos cubiertos del total, para nosotros d = 1 ya que solo se puede llegar al siguiente\n",
    "# baselines.heuristics.py -> get_influence_d\n",
    "# \n",
    "## =================================================================================================\n",
    "n_covered = get_influence(graph, nn_seeds)\n",
    "n, m = graph.vcount(), graph.ecount()\n",
    "## =================================================================================================\n",
    "print(f\"k: {k}. Coverage: {n_covered}/{n}={n_covered/n:.2f}. Time: {t_mean:.2f} ({t_std:.2f})\")\n",
    "model_name = \"GRAT3\"\n",
    "# Write to records\n",
    "records.append({\n",
    "    \"graph\": graph_name,\n",
    "    \"model\": model_name,\n",
    "    \"seed\": seed,\n",
    "    \"n\": n,\n",
    "    \"m\": m,\n",
    "    \"d\": d,\n",
    "    \"k\": k,\n",
    "    \"n_covered\": n_covered,\n",
    "    \"coverage\": n_covered/n,\n",
    "    \"t_mean\": t_mean,\n",
    "    \"t_std\": t_std,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T09:42:57.967876Z",
     "start_time": "2022-10-14T09:42:57.859741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
