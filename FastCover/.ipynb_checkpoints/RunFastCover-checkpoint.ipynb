{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-15T11:52:57.641701Z",
     "start_time": "2022-10-15T11:52:57.619962Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-15T12:20:32.451715Z",
     "start_time": "2022-10-15T12:20:21.040453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dnc-corecipient.txt ...\n",
      "Grafos cargados\n",
      "Greedy influence: 770/906\n",
      "Train influence: 770/770=1.00\n",
      "Train Epoch 0 | Loss: 472.28 | Perf: 1.00 | Elapsed Time: 11.23\n",
      "\n",
      "Validation loss decreased (inf --> -1.000000).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "import igraph\n",
    "import dgl\n",
    "import torch\n",
    "import heapq\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch.softmax import edge_softmax\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"-s\", \"--Seed\", help = \"\", type=int)\n",
    "parser.add_argument(\"-e\", \"--Epochs\", help = \"\", type=int)\n",
    "parser.add_argument(\"-k\", \"--K\", help = \"\", type=int)\n",
    "parser.add_argument(\"-lr\", \"--LearningRate\", help = \"\", type=float)\n",
    "args = parser.parse_args()\n",
    "\n",
    "lr = args.LearningRate\n",
    "n_epoch = args.Epochs\n",
    "k = args.K\n",
    "seed = args.Seed\n",
    "\n",
    "\n",
    "patience = 5\n",
    "n_batch = 10\n",
    "input_dim = 32\n",
    "\n",
    "\n",
    "TRAIN_LIST = ['dnc-corecipient.txt'\n",
    "'as-caida20071105.txt',\n",
    " 'ca-AstroPh.txt',\n",
    " 'dnc-corecipient.txt',\n",
    " 'douban.txt',\n",
    " 'Facebook.txt',\n",
    " 'fb-pages-company.txt',\n",
    " 'fb-pages-food.txt',\n",
    " 'fb-pages-government.txt',\n",
    " 'fb-pages-media.txt',\n",
    " 'fb-pages-politician.txt',\n",
    " 'fb-pages-public-figure.txt',\n",
    " 'fb-pages-sport.txt',\n",
    " 'fb-pages-tvshow.txt',\n",
    " 'git.txt',\n",
    " 'HepPh.txt',\n",
    " 'loc-brightkite_edges.txt',\n",
    " \n",
    " 'moreno_names_names.txt',\n",
    " 'Nethept.txt',\n",
    " 'petster-friendships-hamster-uniq.txt',\n",
    " 'soc-gemsec-HU.txt',\n",
    " 'soc-gemsec-RO.txt',\n",
    " 'soc-hamsterster.txt',\n",
    " 'topology.txt']\n",
    "\n",
    "TEST_LIST = [\n",
    "'DBLP.txt',\n",
    "'facebook-wosn-links.txt',\n",
    "'fb-pages-artist.txt',\n",
    "'soc-gemsec-HR.txt',\n",
    "'loc-gowalla_edges.txt',\n",
    "'Enron.txt'\n",
    "]\n",
    "\n",
    "d = 1\n",
    "\n",
    "HIDDEN_FEATS = [input_dim]*6#, 32, 32, 32, 32, 32]\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "print(f\"\\nInstancias a entrenar: {TRAIN_LIST}\\n\")\n",
    "\n",
    "PATH_TO_TRAIN = \"data/\"\n",
    "PATH_SAVE_TRAINS = \"runs/\"\n",
    "\n",
    "#TRAIN_LIST = get_graph_names(PATH_TO_TRAIN)\n",
    "\n",
    "FEATURE_TYPE = \"1\"\n",
    "directed_train = False\n",
    "use_cuda = False\n",
    "\n",
    "is_directed = False\n",
    "\n",
    "# FUNCTIONS\n",
    "\n",
    "def bfs(graph: igraph.Graph, d: int):\n",
    "    if d <= 1:\n",
    "        return graph.copy()\n",
    "\n",
    "    n = graph.vcount()\n",
    "    es = []\n",
    "\n",
    "    for v in range(n):\n",
    "        layers = [0] * n\n",
    "        visited, queue = set([v]), deque([v])\n",
    "        while queue:\n",
    "            vertex = queue.popleft()\n",
    "            for neighbor in graph.successors(vertex):\n",
    "                if neighbor not in visited and layers[vertex] < d:\n",
    "                    visited.add(neighbor) \n",
    "                    queue.append(neighbor)\n",
    "                    layers[neighbor] = layers[vertex] + 1\n",
    "        visited.remove(v)\n",
    "        es.extend([(v, u) for u in visited])\n",
    "    \n",
    "    extended_graph = igraph.Graph(n=n, directed=True)\n",
    "    extended_graph.add_edges(es)\n",
    "    return extended_graph\n",
    "class Node:\n",
    "    def __init__(self, id, value):\n",
    "        self.id = id\n",
    "        self.value = value\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.value < other.value\n",
    "\n",
    "    def __str__(self):\n",
    "        # we store the negative value to use max heap.\n",
    "        return f\"{self.id}: {-self.value}\"\n",
    "    \n",
    "def greedy(closed_graph: igraph.Graph, k: int, debug=False):\n",
    "    \"\"\"find k-max d-hop cover with greedy\n",
    "\n",
    "    Args:\n",
    "        graph (igraph.Graph): graph\n",
    "        k (int): the number of seeds k\n",
    "        debug (bool): debug mode\n",
    "\n",
    "    Returns:\n",
    "        seeds, covernum: selected seeds, and the seed count\n",
    "    \"\"\"\n",
    "    seeds = []\n",
    "\n",
    "    nodes_num = closed_graph.vcount()\n",
    "    covered = [False] * nodes_num\n",
    "    cover_num = 0\n",
    "\n",
    "    inf_list = [deg + 1 for deg in closed_graph.outdegree()]\n",
    "\n",
    "    node_queue = [Node(i, -inf_list[i]) for i in range(nodes_num)]\n",
    "    heapq.heapify(node_queue)\n",
    "    i = 0\n",
    "\n",
    "    while i < k and cover_num < nodes_num:  # while there's still free point or unused budget\n",
    "\n",
    "        # Find the node with max marginal utility\n",
    "        max_inf_node = heapq.heappop(node_queue)\n",
    "        if inf_list[max_inf_node.id] != - max_inf_node.value:\n",
    "            max_inf_node.value = -inf_list[max_inf_node.id]\n",
    "            heapq.heappush(node_queue, max_inf_node)\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "        seeds.append(max_inf_node.id)\n",
    "        if not covered[max_inf_node.id]:  # Update predecessors\n",
    "            covered[max_inf_node.id] = True  # 1. mark max_node as covered\n",
    "            cover_num += 1\n",
    "            inf_list[max_inf_node.id] -= 1\n",
    "            # 2. all the preds have influence -1\n",
    "            for predecessor in closed_graph.predecessors(max_inf_node.id):\n",
    "                inf_list[predecessor] -= 1\n",
    "\n",
    "        # Update successors\n",
    "        for successor in closed_graph.successors(max_inf_node.id):\n",
    "            if not covered[successor]:\n",
    "                # 1. mark all the successors as covered\n",
    "                covered[successor] = True\n",
    "                cover_num += 1\n",
    "                # 2. all the successors have influence -1 (since there is no unitility to cover themselves)\n",
    "                inf_list[successor] -= 1\n",
    "                # 3. all the (predecessors of successors) have influence -1\n",
    "                for predecessor in closed_graph.predecessors(successor):\n",
    "                    inf_list[predecessor] -= 1\n",
    "\n",
    "        if debug:\n",
    "            print(\n",
    "                f\"Round {i}: {max_inf_node.id} is selected. {cover_num} nodes are covered.\")\n",
    "                \n",
    "    return seeds, cover_num\n",
    "\n",
    "\n",
    "def get_adj_mat(graph, d=1):\n",
    "    if d == 1:\n",
    "        adj_mat = np.array(graph.get_adjacency().data, dtype=bool)\n",
    "        adj_mat = torch.from_numpy(np.array(adj_mat, dtype=int)).float().cpu()\n",
    "        adj_mat += torch.eye(graph.vcount()).cpu()\n",
    "        return adj_mat.cpu()\n",
    "    elif d == 2:\n",
    "        return get_adj_mat_2(graph)\n",
    "    \n",
    "def get_graph_names(path_to_test):\n",
    "    graph_names = []\n",
    "    for rt, _, files in os.walk(path_to_test):\n",
    "        if rt == path_to_test:\n",
    "            for file in files:\n",
    "                if file.endswith('.txt'):\n",
    "                    graph_names.append(file)\n",
    "    return graph_names\n",
    "\n",
    "\n",
    "def gen_zero_feature(graph, feature_dim):\n",
    "    \"\"\"Generate all-zero features\n",
    "    \"\"\"\n",
    "    return torch.zeros(graph.vcount(), feature_dim)\n",
    "\n",
    "\n",
    "def gen_one_feature(graph, feature_dim):\n",
    "    \"\"\"Generate all-one features\n",
    "    \"\"\"\n",
    "    return torch.ones(graph.vcount(), feature_dim)\n",
    "\n",
    "\n",
    "def gen_deg_feature(graph, *args):  # args is only a placeholder\n",
    "    indegree = torch.tensor(graph.indegree()).float()\n",
    "    zeros = torch.zeros(graph.vcount(), 1).squeeze(1)\n",
    "    return torch.stack([indegree, zeros], dim=1)\n",
    "\n",
    "\n",
    "def gen_one_hot_feayture(graph, *args):  # args is only a placeholder\n",
    "    return torch.eye(graph.vcount()).float()\n",
    "\n",
    "\n",
    "FEATURE_TYPE_DICT = {\n",
    "    \"0\": gen_zero_feature,\n",
    "    \"1\": gen_one_feature,\n",
    "    \"onehot\": gen_one_hot_feayture,\n",
    "    \"deg\": gen_deg_feature,\n",
    "}\n",
    "\n",
    "def get_rev_dgl(graph, feature_type='0', feature_dim=None, is_directed=False, use_cuda=False):\n",
    "    \"\"\"get dgl graph from igraph\n",
    "    \"\"\"\n",
    "    \n",
    "    src, dst = zip(*graph.get_edgelist())\n",
    "\n",
    "    if use_cuda:\n",
    "        dglgraph = dgl.graph((dst, src)).to(torch.device(\"cuda:0\"))\n",
    "    else:\n",
    "        dglgraph = dgl.graph((dst, src))\n",
    "        \n",
    "    if not is_directed:\n",
    "        dglgraph.add_edges(src, dst)\n",
    "\n",
    "    if use_cuda:\n",
    "        dglgraph.ndata['feat'] = FEATURE_TYPE_DICT[feature_type](graph, feature_dim).cuda()\n",
    "        dglgraph.ndata['degree'] = torch.tensor(graph.degree()).float().cuda()\n",
    "\n",
    "    else:\n",
    "        dglgraph.ndata['feat'] = FEATURE_TYPE_DICT[feature_type](graph, feature_dim)\n",
    "        dglgraph.ndata['degree'] = torch.tensor(graph.degree()).float()\n",
    "        \n",
    "    return dglgraph\n",
    "\n",
    "\n",
    "\n",
    "# Guanhao's GRAT\n",
    "class GRATLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        # TODO: why not another linear layer before entering the net\n",
    "        super(GRATLayer, self).__init__()\n",
    "        # linear layer\n",
    "        self.fc = nn.Linear(in_feats, out_feats, bias=True)  # bias=True in Guanhao's original code\n",
    "        \n",
    "        # attention layer\n",
    "        self.attn_fc = nn.Linear(2 * in_feats, 1, bias=True)  # bias=True in Guanhao's original code\n",
    "\n",
    "        # initialize parameters\n",
    "        # self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        h2 = torch.cat([edges.src['h'], edges.dst['h']], dim=1)\n",
    "        a = self.attn_fc(h2)\n",
    "        return {'e': torch.relu(a)}\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        return {'h': edges.src['h'] * edges.data['alpha']}  # message divided by weight\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        return {'h': torch.sum(nodes.mailbox['h'], dim=1)}\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = feature\n",
    "            # Equation (2)\n",
    "            g.apply_edges(self.edge_attention)  # calculate e_{ij}\n",
    "\n",
    "            # Calculate softmax on source code -> on the reversed graph\n",
    "            rg = g.reverse(copy_ndata=False, copy_edata=True)\n",
    "            g.edata['alpha'] = edge_softmax(rg, rg.edata['e'])\n",
    "            \n",
    "            # Convolution\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            \n",
    "            g.ndata['h'] = self.fc(g.ndata['h'])\n",
    "            h = g.ndata['h']\n",
    "            return h\n",
    "\n",
    "\n",
    "# GRAT more similar to GAT \n",
    "class GRATVLayer(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GRATVLayer, self).__init__()\n",
    "        # linear layer\n",
    "        self.fc = nn.Linear(in_feats, out_feats, bias=False)  # bias=True in Guanhao's original code\n",
    "        # attention layer\n",
    "        self.attn_fc = nn.Linear(2 * out_feats, 1, bias=False)  # bias=True in Guanhao's original code\n",
    "        # initialize parameters\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.attn_fc.weight, gain=gain)\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "        return {'e': F.leaky_relu(a)}\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        return {'h': edges.src['z'] * edges.data['alpha']}  # message divided by weight\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        return {'h': torch.sum(nodes.mailbox['h'], dim=1)}\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        with g.local_scope():\n",
    "            z = self.fc(feature)\n",
    "            g.ndata['z'] = z\n",
    "            # Equation (2)\n",
    "            g.apply_edges(self.edge_attention)  # calculate e_{ij}\n",
    "            # Calculate softmax on source code -> on the reversed graph\n",
    "            rg = g.reverse(copy_ndata=False, copy_edata=True)\n",
    "            g.edata['alpha'] = edge_softmax(rg, rg.edata['e'])\n",
    "            # Equation (3)\n",
    "            g.update_all(self.message_func, self.reduce_func)\n",
    "            # output            \n",
    "            h = g.ndata['h']\n",
    "            return h\n",
    "\n",
    "        \n",
    "class GRAT3_(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats1, hidden_feats2, out_feats, *args):\n",
    "        super(GRAT3_, self).__init__()\n",
    "        self.grat1 = GRATLayer(in_feats, hidden_feats1)\n",
    "        self.grat2 = GRATLayer(hidden_feats1, hidden_feats2)\n",
    "        self.grat3 = GRATLayer(hidden_feats2, out_feats)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        h = torch.relu(self.grat1(g, feature))\n",
    "        h = torch.relu(self.grat2(g, h))\n",
    "        h = self.grat3(g, h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class GRAT3(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats1, hidden_feats2, *args):\n",
    "        super(GRAT3, self).__init__()\n",
    "        self.grat = GRAT3_(in_feats, hidden_feats1, hidden_feats2, 1, *args)  # out_feats=1\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        h = self.grat(g, feature)\n",
    "        h = torch.sigmoid(h)\n",
    "        return h\n",
    "    \n",
    "    \n",
    "def get_influence(graph, seeds):\n",
    "    if torch.is_tensor(seeds):\n",
    "        seeds = seeds.int().tolist()\n",
    "\n",
    "    covered = set()\n",
    "    for seed in seeds:\n",
    "        covered.add(int(seed))\n",
    "        for u in graph.successors(seed):  # Add all the covered seeds\n",
    "            covered.add(u)\n",
    "    return len(covered)\n",
    "\n",
    "class KSetMaxCoverLoss(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "\n",
    "    def forward(self, v, graph, *args):\n",
    "        adj_mat = np.array(graph.get_adjacency().data, dtype=np.int32)\n",
    "        adj_mat = torch.from_numpy(np.array(adj_mat, dtype=int)).float()\n",
    "        adj_mat += torch.eye(graph.vcount())\n",
    "        adj_mat = adj_mat.cpu()\n",
    "        tmp = 1 - v.unsqueeze(1) * adj_mat\n",
    "        tmp = torch.prod(tmp, dim=0)\n",
    "        loss1 = torch.sum(tmp)\n",
    "        loss2 = torch.sum(v)\n",
    "        return loss1 + self.C * loss2\n",
    "\n",
    "\n",
    "class KSetMaxCoverAdjLoss(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "\n",
    "    def forward(self, v, adj_mat, *args):\n",
    "        tmp = 1 - v.unsqueeze(1) * adj_mat.cpu()\n",
    "        tmp = torch.prod(tmp, dim=0)\n",
    "        loss1 = torch.sum(tmp)\n",
    "        loss2 = torch.sum(v)\n",
    "        return loss1 + self.C * loss2\n",
    "\n",
    "\n",
    "class KSetMaxCoverLossSigmoid(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "\n",
    "    def forward(self, v, graph, k):\n",
    "        print(0, flush=True)\n",
    "        adj_mat = np.array(graph.get_adjacency().data, dtype=np.int32)\n",
    "        #adj_mat = torch.from_numpy(np.array(adj_mat, dtype=int)).float().cpu()  # TODO: make it adaptive to non-cuda env\n",
    "        adj_mat = torch.from_numpy(np.array(adj_mat, dtype=int)).float().cuda()  # TODO: make it adaptive to non-cuda env\n",
    "        adj_mat += torch.eye(graph.vcount())\n",
    "        v = torch.sigmoid(v)\n",
    "        print(1, flush=True)\n",
    "        tmp = 1 - v.unsqueeze(1)*adj_mat\n",
    "        print(2, flush=True)\n",
    "        tmp = torch.prod(tmp, dim=0)\n",
    "        loss1 = torch.sum(tmp)\n",
    "        loss2 = torch.relu(torch.sum(v)-k)  # Loss with threshold (hinge loss-like)\n",
    "        return loss1 + self.C * loss2\n",
    "\n",
    "    \n",
    "    \n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "        \n",
    "        \n",
    "def train_single(net, optimizer, n_epoch, loss_function, adj_mat, graph, dglgraph, greedy_perf, k, closed_graph=None):\n",
    "    \"\"\"helper function of train\n",
    "    \"\"\"\n",
    "    loss_list = []\n",
    "    for _ in range(n_epoch):\n",
    "        out = net(dglgraph, dglgraph.ndata['feat']).squeeze(1)\n",
    "        loss = loss_function(out, adj_mat)\n",
    "        loss_list.append(float(loss.data))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    logits = net.grat(dglgraph, dglgraph.ndata['feat']).squeeze(\n",
    "        1)\n",
    "        \n",
    "    _, indices = torch.topk(logits, k)\n",
    "\n",
    "    if closed_graph is None:\n",
    "        train_perf = get_influence(graph, indices)\n",
    "    else:\n",
    "        train_perf = get_influence(closed_graph, indices)\n",
    "    \n",
    "    perf_ratio = train_perf/greedy_perf\n",
    "    print(f\"Train influence: {train_perf}/{greedy_perf}={perf_ratio:.2f}\")\n",
    "    return loss_list, perf_ratio\n",
    "\n",
    "\n",
    "graphs = []\n",
    "dglgraphs = []\n",
    "\n",
    "for file in TRAIN_LIST:\n",
    "    \n",
    "    print(f\"Cargando {file} ...\")\n",
    "    graph = igraph.Graph().Read_Edgelist(\n",
    "        f\"{PATH_TO_TRAIN}{file}\", directed=False)\n",
    "\n",
    "    graphs.append(graph)\n",
    "    \n",
    "    dglgraph = get_rev_dgl(graph, FEATURE_TYPE, input_dim, directed_train, use_cuda)\n",
    "    \n",
    "    dglgraphs.append(dglgraph)\n",
    "\n",
    "print(\"Grafos cargados.\\n\")\n",
    "\n",
    "adj_matrices = []\n",
    "greedy_perfs = []\n",
    "closed_graphs = []\n",
    "\n",
    "for graph in graphs:\n",
    "    \n",
    "    closed_graph = bfs(graph, d)\n",
    "    closed_graphs.append(closed_graph)\n",
    "    \n",
    "    adj_matrix = get_adj_mat(closed_graph)\n",
    "    adj_matrices.append(adj_matrix)\n",
    "    \n",
    "    _, n_covered = greedy(closed_graph, k=k)\n",
    "    \n",
    "    greedy_perfs.append(n_covered)\n",
    "    \n",
    "    print(f\"Greedy influence: {n_covered}/{closed_graph.vcount()}\\n\")    \n",
    "    \n",
    "\n",
    "net = GRAT3(*HIDDEN_FEATS)\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    \n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# EarlyStopping Module\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "avg_train_losses = []\n",
    "avg_valid_losses = [] \n",
    "\n",
    "# cover performence\n",
    "train_perfs = []\n",
    "avg_train_perfs = []\n",
    "# initialize the early_stopping object\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "if closed_graph is None:\n",
    "    closed_graph = [None] * len(graphs)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    timer = time.time()\n",
    "    for adj_mat, graph, dglgraph, greedy_perf, closed_graph in zip(adj_matrices, graphs, dglgraphs, greedy_perfs, closed_graphs):\n",
    "        # train the i_th graph\n",
    "        loss_list, perf = train_single(\n",
    "            net, optimizer, n_batch, KSetMaxCoverAdjLoss(1), adj_mat, graph, dglgraph, greedy_perf, k, closed_graph\n",
    "        )\n",
    "        train_perfs.append(perf)\n",
    "        train_losses.append(sum(loss_list)/n_batch)  # track losses\n",
    "\n",
    "    train_loss = np.average(train_losses)\n",
    "    avg_train_losses.append(train_loss)\n",
    "\n",
    "    train_perf = np.average(train_perfs)\n",
    "    avg_train_perfs.append(train_perf)\n",
    "\n",
    "    #logging.info(f\"Train Epoch {epoch} | Loss: {train_loss:.2f} | Perf: {train_perf:.2f} | Elapsed Time: {time.time() - timer:.2f}\")\n",
    "    print(f\"Train Epoch {epoch} | Loss: {train_loss:.2f} | Perf: {train_perf:.2f} | Elapsed Time: {time.time() - timer:.2f}\")\n",
    "    print()\n",
    "    \n",
    "    if epoch%5 == 0 and epoch != 0:\n",
    "        torch.save(net.state_dict(), f=f\"{save_filename}-epoch-{epoch}.pt\")\n",
    "        print(f\"Epoch {epoch} saved.\\n\")\n",
    "\n",
    "    # clear lists to track next epoch\n",
    "    train_losses = []\n",
    "    train_perfs = []\n",
    "    # valid_losses = []\n",
    "\n",
    "    # early_stopping(train_loss, net)\n",
    "    early_stopping(-train_perf, net)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "# load the last checkpoint with the best model\n",
    "net.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "net.cpu()\n",
    "\n",
    "dt_string = datetime.now().strftime(\"%m-%d_%H-%M\")\n",
    "torch.save(net.state_dict(), f=f\"{PATH_SAVE_TRAINS}{'GRAT'}_seed_{seed}_{dt_string}.pt\")  # Change the path\n",
    "with open(f\"{PATH_SAVE_TRAINS}{'GRAT'}_seed_{seed}_k_{dt_string}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(loss_list, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-15T11:51:47.333425Z",
     "start_time": "2022-10-15T11:51:47.322953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now = 2022-10-15 13:51:47.324015\n",
      "date and time = 10-15_13:51\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
